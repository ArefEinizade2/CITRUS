{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetrLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/benaziza-22/anaconda3/envs/ima/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "import os\n",
    "import torch\n",
    "import tsl\n",
    "from tsl.metrics.torch import MaskedMSE, MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Molene')\n",
    "from layers import CITRUS\n",
    "\n",
    "import networkx as nx\n",
    "from Utilsss import get_evcs_evals\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from tsl.data import SpatioTemporalDataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsl.ops.connectivity import edge_index_to_adj\n",
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "from tsl.data.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_evec_evals(L_normalized_sparse_list, k_list):\n",
    "    evals, evecs = sparse.linalg.eigs(L_normalized_sparse_list[0], k=k_list[0], return_eigenvectors=True)\n",
    "    evals = torch.tensor(evals.real)\n",
    "    evals = evals.to(torch.float32)\n",
    "    evals_list = [evals]\n",
    "    evecs=torch.tensor(evecs.real).to(torch.float32)        \n",
    "    evecs_kron = evecs\n",
    "    \n",
    "    for p in range(1, len(L_normalized_sparse_list)):\n",
    "\n",
    "        evals, evecs = sparse.linalg.eigs(L_normalized_sparse_list[p], k=k_list[p], return_eigenvectors=True)\n",
    "        evals = torch.tensor(evals.real)\n",
    "        evals = evals.to(torch.float32)\n",
    "        evals_list.append(evals)\n",
    "        evecs = torch.tensor(evecs.real)        \n",
    "        evecs_kron = torch.kron(evecs_kron, evecs).to(torch.float32)\n",
    "    \n",
    "    return evals_list, evecs_kron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 6\n",
    "M_hat = M\n",
    "n_epochs = 300\n",
    "val_len = 0.1\n",
    "test_len = 0.1\n",
    "lr = 1e-2\n",
    "batch_size = 2048\n",
    "enable_progress_bar = True\n",
    "horizon = 12\n",
    "emb_size = 16    #@param\n",
    "hidden_size = 32   #@param\n",
    "rnn_layers = 1     #@param\n",
    "gnn_kernel = 2   #@param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = './MetrLA_Results/'\n",
    "\n",
    "if not os.path.isdir(destination_path):  \n",
    "    os.mkdir(destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.3.0\n",
      "  PyG version: 2.6.1\n",
      "  tsl version: 0.9.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"  PyG version: {torch_geometric.__version__}\")\n",
    "print(f\"  tsl version: {tsl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions ###############\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(edgeitems=3, precision=3)\n",
    "torch.set_printoptions(edgeitems=2, precision=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions ################\n",
    "def print_matrix(matrix):\n",
    "    return pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetrLA(length=34272, n_nodes=207, n_channels=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/benaziza-22/anaconda3/envs/ima/lib/python3.12/site-packages/tsl/datasets/metr_la.py:98: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  date_range = pd.date_range(df.index[0], df.index[-1], freq='5T')\n",
      "/home/infres/benaziza-22/anaconda3/envs/ima/lib/python3.12/site-packages/tsl/datasets/metr_la.py:109: FutureWarning: The 'method' keyword in DataFrame.replace is deprecated and will be removed in a future version.\n",
      "  df = df.replace(to_replace=0., method='ffill')\n"
     ]
    }
   ],
   "source": [
    "from tsl.datasets import MetrLA\n",
    "\n",
    "dataset = MetrLA(root='./MetrLA')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling period: <5 * Minutes>\n",
      "Has missing values: True\n",
      "Has exogenous variables: True\n",
      "Covariates: dist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <th>773869</th>\n",
       "      <th>767541</th>\n",
       "      <th>767542</th>\n",
       "      <th>717447</th>\n",
       "      <th>717446</th>\n",
       "      <th>717445</th>\n",
       "      <th>773062</th>\n",
       "      <th>767620</th>\n",
       "      <th>737529</th>\n",
       "      <th>717816</th>\n",
       "      <th>...</th>\n",
       "      <th>772167</th>\n",
       "      <th>769372</th>\n",
       "      <th>774204</th>\n",
       "      <th>769806</th>\n",
       "      <th>717590</th>\n",
       "      <th>717592</th>\n",
       "      <th>717595</th>\n",
       "      <th>772168</th>\n",
       "      <th>718141</th>\n",
       "      <th>769373</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channels</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:00:00</th>\n",
       "      <td>64.38</td>\n",
       "      <td>67.62</td>\n",
       "      <td>67.12</td>\n",
       "      <td>61.50</td>\n",
       "      <td>66.88</td>\n",
       "      <td>68.75</td>\n",
       "      <td>65.12</td>\n",
       "      <td>67.12</td>\n",
       "      <td>59.62</td>\n",
       "      <td>62.75</td>\n",
       "      <td>...</td>\n",
       "      <td>45.62</td>\n",
       "      <td>65.50</td>\n",
       "      <td>64.50</td>\n",
       "      <td>66.43</td>\n",
       "      <td>66.88</td>\n",
       "      <td>59.38</td>\n",
       "      <td>69.00</td>\n",
       "      <td>59.25</td>\n",
       "      <td>69.00</td>\n",
       "      <td>61.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:05:00</th>\n",
       "      <td>62.67</td>\n",
       "      <td>68.56</td>\n",
       "      <td>65.44</td>\n",
       "      <td>62.44</td>\n",
       "      <td>64.44</td>\n",
       "      <td>68.11</td>\n",
       "      <td>65.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>57.44</td>\n",
       "      <td>63.33</td>\n",
       "      <td>...</td>\n",
       "      <td>50.67</td>\n",
       "      <td>69.88</td>\n",
       "      <td>66.67</td>\n",
       "      <td>58.56</td>\n",
       "      <td>62.00</td>\n",
       "      <td>61.11</td>\n",
       "      <td>64.44</td>\n",
       "      <td>55.89</td>\n",
       "      <td>68.44</td>\n",
       "      <td>62.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:10:00</th>\n",
       "      <td>64.00</td>\n",
       "      <td>63.75</td>\n",
       "      <td>60.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.25</td>\n",
       "      <td>64.50</td>\n",
       "      <td>64.25</td>\n",
       "      <td>63.88</td>\n",
       "      <td>65.38</td>\n",
       "      <td>...</td>\n",
       "      <td>44.12</td>\n",
       "      <td>69.00</td>\n",
       "      <td>56.50</td>\n",
       "      <td>59.25</td>\n",
       "      <td>68.12</td>\n",
       "      <td>62.50</td>\n",
       "      <td>65.62</td>\n",
       "      <td>61.38</td>\n",
       "      <td>69.86</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:15:00</th>\n",
       "      <td>64.00</td>\n",
       "      <td>63.75</td>\n",
       "      <td>60.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.25</td>\n",
       "      <td>64.50</td>\n",
       "      <td>64.25</td>\n",
       "      <td>63.88</td>\n",
       "      <td>65.38</td>\n",
       "      <td>...</td>\n",
       "      <td>44.12</td>\n",
       "      <td>69.00</td>\n",
       "      <td>56.50</td>\n",
       "      <td>59.25</td>\n",
       "      <td>68.12</td>\n",
       "      <td>62.50</td>\n",
       "      <td>65.62</td>\n",
       "      <td>61.38</td>\n",
       "      <td>69.86</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:20:00</th>\n",
       "      <td>64.00</td>\n",
       "      <td>63.75</td>\n",
       "      <td>60.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>66.50</td>\n",
       "      <td>66.25</td>\n",
       "      <td>64.50</td>\n",
       "      <td>64.25</td>\n",
       "      <td>63.88</td>\n",
       "      <td>65.38</td>\n",
       "      <td>...</td>\n",
       "      <td>44.12</td>\n",
       "      <td>69.00</td>\n",
       "      <td>56.50</td>\n",
       "      <td>59.25</td>\n",
       "      <td>68.12</td>\n",
       "      <td>62.50</td>\n",
       "      <td>65.62</td>\n",
       "      <td>61.38</td>\n",
       "      <td>69.86</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:35:00</th>\n",
       "      <td>65.00</td>\n",
       "      <td>65.89</td>\n",
       "      <td>68.56</td>\n",
       "      <td>61.67</td>\n",
       "      <td>32.83</td>\n",
       "      <td>54.56</td>\n",
       "      <td>62.44</td>\n",
       "      <td>63.33</td>\n",
       "      <td>59.22</td>\n",
       "      <td>65.33</td>\n",
       "      <td>...</td>\n",
       "      <td>52.89</td>\n",
       "      <td>69.00</td>\n",
       "      <td>65.11</td>\n",
       "      <td>55.67</td>\n",
       "      <td>66.33</td>\n",
       "      <td>62.44</td>\n",
       "      <td>66.78</td>\n",
       "      <td>64.89</td>\n",
       "      <td>69.67</td>\n",
       "      <td>62.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:40:00</th>\n",
       "      <td>61.38</td>\n",
       "      <td>65.62</td>\n",
       "      <td>66.50</td>\n",
       "      <td>62.75</td>\n",
       "      <td>32.83</td>\n",
       "      <td>50.50</td>\n",
       "      <td>62.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>65.25</td>\n",
       "      <td>67.12</td>\n",
       "      <td>...</td>\n",
       "      <td>54.00</td>\n",
       "      <td>69.25</td>\n",
       "      <td>60.12</td>\n",
       "      <td>60.50</td>\n",
       "      <td>67.25</td>\n",
       "      <td>59.38</td>\n",
       "      <td>66.00</td>\n",
       "      <td>61.25</td>\n",
       "      <td>69.00</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:45:00</th>\n",
       "      <td>67.00</td>\n",
       "      <td>59.67</td>\n",
       "      <td>69.56</td>\n",
       "      <td>61.00</td>\n",
       "      <td>32.83</td>\n",
       "      <td>44.78</td>\n",
       "      <td>64.22</td>\n",
       "      <td>63.78</td>\n",
       "      <td>59.78</td>\n",
       "      <td>57.67</td>\n",
       "      <td>...</td>\n",
       "      <td>51.33</td>\n",
       "      <td>67.89</td>\n",
       "      <td>64.33</td>\n",
       "      <td>57.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>62.67</td>\n",
       "      <td>68.67</td>\n",
       "      <td>63.33</td>\n",
       "      <td>67.44</td>\n",
       "      <td>61.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:50:00</th>\n",
       "      <td>66.75</td>\n",
       "      <td>62.25</td>\n",
       "      <td>66.00</td>\n",
       "      <td>59.62</td>\n",
       "      <td>32.83</td>\n",
       "      <td>53.00</td>\n",
       "      <td>64.29</td>\n",
       "      <td>64.12</td>\n",
       "      <td>60.88</td>\n",
       "      <td>66.25</td>\n",
       "      <td>...</td>\n",
       "      <td>51.12</td>\n",
       "      <td>69.38</td>\n",
       "      <td>61.62</td>\n",
       "      <td>60.50</td>\n",
       "      <td>65.62</td>\n",
       "      <td>66.38</td>\n",
       "      <td>69.50</td>\n",
       "      <td>63.00</td>\n",
       "      <td>67.88</td>\n",
       "      <td>63.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:55:00</th>\n",
       "      <td>65.11</td>\n",
       "      <td>66.89</td>\n",
       "      <td>66.78</td>\n",
       "      <td>61.22</td>\n",
       "      <td>32.83</td>\n",
       "      <td>49.56</td>\n",
       "      <td>65.78</td>\n",
       "      <td>65.11</td>\n",
       "      <td>63.00</td>\n",
       "      <td>61.67</td>\n",
       "      <td>...</td>\n",
       "      <td>56.00</td>\n",
       "      <td>67.44</td>\n",
       "      <td>64.89</td>\n",
       "      <td>60.89</td>\n",
       "      <td>64.22</td>\n",
       "      <td>66.44</td>\n",
       "      <td>68.44</td>\n",
       "      <td>63.56</td>\n",
       "      <td>68.67</td>\n",
       "      <td>61.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34272 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "nodes               773869 767541 767542 717447 717446 717445 773062 767620  \\\n",
       "channels                 0      0      0      0      0      0      0      0   \n",
       "2012-03-01 00:00:00  64.38  67.62  67.12  61.50  66.88  68.75  65.12  67.12   \n",
       "2012-03-01 00:05:00  62.67  68.56  65.44  62.44  64.44  68.11  65.00  65.00   \n",
       "2012-03-01 00:10:00  64.00  63.75  60.00  59.00  66.50  66.25  64.50  64.25   \n",
       "2012-03-01 00:15:00  64.00  63.75  60.00  59.00  66.50  66.25  64.50  64.25   \n",
       "2012-03-01 00:20:00  64.00  63.75  60.00  59.00  66.50  66.25  64.50  64.25   \n",
       "...                    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2012-06-27 23:35:00  65.00  65.89  68.56  61.67  32.83  54.56  62.44  63.33   \n",
       "2012-06-27 23:40:00  61.38  65.62  66.50  62.75  32.83  50.50  62.00  67.00   \n",
       "2012-06-27 23:45:00  67.00  59.67  69.56  61.00  32.83  44.78  64.22  63.78   \n",
       "2012-06-27 23:50:00  66.75  62.25  66.00  59.62  32.83  53.00  64.29  64.12   \n",
       "2012-06-27 23:55:00  65.11  66.89  66.78  61.22  32.83  49.56  65.78  65.11   \n",
       "\n",
       "nodes               737529 717816  ... 772167 769372 774204 769806 717590  \\\n",
       "channels                 0      0  ...      0      0      0      0      0   \n",
       "2012-03-01 00:00:00  59.62  62.75  ...  45.62  65.50  64.50  66.43  66.88   \n",
       "2012-03-01 00:05:00  57.44  63.33  ...  50.67  69.88  66.67  58.56  62.00   \n",
       "2012-03-01 00:10:00  63.88  65.38  ...  44.12  69.00  56.50  59.25  68.12   \n",
       "2012-03-01 00:15:00  63.88  65.38  ...  44.12  69.00  56.50  59.25  68.12   \n",
       "2012-03-01 00:20:00  63.88  65.38  ...  44.12  69.00  56.50  59.25  68.12   \n",
       "...                    ...    ...  ...    ...    ...    ...    ...    ...   \n",
       "2012-06-27 23:35:00  59.22  65.33  ...  52.89  69.00  65.11  55.67  66.33   \n",
       "2012-06-27 23:40:00  65.25  67.12  ...  54.00  69.25  60.12  60.50  67.25   \n",
       "2012-06-27 23:45:00  59.78  57.67  ...  51.33  67.89  64.33  57.00  66.00   \n",
       "2012-06-27 23:50:00  60.88  66.25  ...  51.12  69.38  61.62  60.50  65.62   \n",
       "2012-06-27 23:55:00  63.00  61.67  ...  56.00  67.44  64.89  60.89  64.22   \n",
       "\n",
       "nodes               717592 717595 772168 718141 769373  \n",
       "channels                 0      0      0      0      0  \n",
       "2012-03-01 00:00:00  59.38  69.00  59.25  69.00  61.88  \n",
       "2012-03-01 00:05:00  61.11  64.44  55.89  68.44  62.88  \n",
       "2012-03-01 00:10:00  62.50  65.62  61.38  69.86  62.00  \n",
       "2012-03-01 00:15:00  62.50  65.62  61.38  69.86  62.00  \n",
       "2012-03-01 00:20:00  62.50  65.62  61.38  69.86  62.00  \n",
       "...                    ...    ...    ...    ...    ...  \n",
       "2012-06-27 23:35:00  62.44  66.78  64.89  69.67  62.33  \n",
       "2012-06-27 23:40:00  59.38  66.00  61.25  69.00  62.00  \n",
       "2012-06-27 23:45:00  62.67  68.67  63.33  67.44  61.22  \n",
       "2012-06-27 23:50:00  66.38  69.50  63.00  67.88  63.50  \n",
       "2012-06-27 23:55:00  66.44  68.44  63.56  68.67  61.78  \n",
       "\n",
       "[34272 rows x 207 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Sampling period: {dataset.freq}\")\n",
    "print(f\"Has missing values: {dataset.has_mask}\")\n",
    "print(f\"Has exogenous variables: {dataset.has_covariates}\")\n",
    "print(f\"Covariates: {', '.join(dataset.covariates.keys())}\")\n",
    "\n",
    "print_matrix(dataset.dist)\n",
    "dataset.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default similarity: distance\n",
      "Available similarity options: {'distance'}\n",
      "==========================================\n",
      "Similarity matrix W:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  197  198  199  \\\n",
       "0   1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00 0.12   \n",
       "1   0.00 1.00 0.39 0.00 0.00 0.00 0.00 0.39 0.00 0.00  ... 0.00 0.00 0.00   \n",
       "2   0.00 0.72 1.00 0.00 0.00 0.00 0.00 0.09 0.00 0.00  ... 0.00 0.00 0.00   \n",
       "3   0.00 0.00 0.00 1.00 0.63 0.00 0.01 0.00 0.00 0.00  ... 0.00 0.01 0.00   \n",
       "4   0.00 0.00 0.00 0.63 1.00 0.05 0.14 0.00 0.00 0.00  ... 0.00 0.00 0.00   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "202 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00 0.00   \n",
       "203 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00 0.00   \n",
       "204 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.22  ... 0.13 0.00 0.00   \n",
       "205 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00 0.00   \n",
       "206 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.32 0.00   \n",
       "\n",
       "     200  201  202  203  204  205  206  \n",
       "0   0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "1   0.00 0.03 0.00 0.00 0.00 0.00 0.00  \n",
       "2   0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "3   0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "4   0.00 0.00 0.00 0.00 0.00 0.00 0.00  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "202 0.00 0.00 1.00 0.08 0.00 0.00 0.00  \n",
       "203 0.00 0.00 0.00 1.00 0.00 0.00 0.00  \n",
       "204 0.00 0.00 0.00 0.00 1.00 0.00 0.00  \n",
       "205 0.00 0.00 0.00 0.00 0.00 1.00 0.00  \n",
       "206 0.00 0.00 0.00 0.00 0.00 0.00 1.00  \n",
       "\n",
       "[207 rows x 207 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Default similarity: {dataset.similarity_score}\")\n",
    "print(f\"Available similarity options: {dataset.similarity_options}\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "sim = dataset.get_similarity(\"distance\")  # or dataset.compute_similarity()\n",
    "\n",
    "print(\"Similarity matrix W:\")\n",
    "print_matrix(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index (2, 2626):\n",
      " [[  0   0   0 ... 206 206 206]\n",
      " [ 13  36  37 ... 163 187 198]]\n",
      "edge_weight (2626,):\n",
      " [0.261 0.519 0.509 ... 0.621 0.278 0.649]\n"
     ]
    }
   ],
   "source": [
    "connectivity = dataset.get_connectivity(threshold=0.1,\n",
    "                                        include_self=False,\n",
    "                                        layout=\"edge_index\",\n",
    "                                        force_symmetric=True)\n",
    "\n",
    "edge_index, edge_weight = connectivity\n",
    "\n",
    "print(f'edge_index {edge_index.shape}:\\n', edge_index)\n",
    "print(f'edge_weight {edge_weight.shape}:\\n', edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (207, 207):\n",
      "Sparse edge weights:\n",
      " [0.261 0.519 0.509 ... 0.621 0.278 0.649]\n"
     ]
    }
   ],
   "source": [
    "from tsl.ops.connectivity import edge_index_to_adj\n",
    "\n",
    "adj = edge_index_to_adj(edge_index, edge_weight)\n",
    "print(f'A {adj.shape}:')\n",
    "print_matrix(adj)\n",
    "print(f'Sparse edge weights:\\n', adj[edge_index[1], edge_index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataset(n_samples=34255, n_nodes=207, n_channels=1)\n"
     ]
    }
   ],
   "source": [
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      connectivity=connectivity,\n",
    "                                      mask=dataset.mask,\n",
    "                                      horizon=horizon,\n",
    "                                      window=M_hat,\n",
    "                                      stride=1)\n",
    "print(torch_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(\n",
      "  input=(x=[t=6, n=207, f=1], edge_index=[2, e=2626], edge_weight=[e=2626]),\n",
      "  target=(y=[t=12, n=207, f=1]),\n",
      "  has_mask=True\n",
      ")\n",
      "tensor([[[True],\n",
      "         [True],\n",
      "         ...,\n",
      "         [True],\n",
      "         [True]],\n",
      "\n",
      "        [[True],\n",
      "         [True],\n",
      "         ...,\n",
      "         [True],\n",
      "         [True]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[True],\n",
      "         [True],\n",
      "         ...,\n",
      "         [True],\n",
      "         [True]],\n",
      "\n",
      "        [[True],\n",
      "         [True],\n",
      "         ...,\n",
      "         [True],\n",
      "         [True]]])\n",
      "Sample has no transformation functions.\n",
      "{'x': 't n f', 'mask': 't n f', 'edge_index': '2 e', 'edge_weight': 'e', 'y': 't n f'}\n",
      "==================   Or we can print patterns and shapes together   ==================\n",
      "Data(\n",
      "  input=(x=[t=6, n=207, f=1], edge_index=[2, e=2626], edge_weight=[e=2626]),\n",
      "  target=(y=[t=12, n=207, f=1]),\n",
      "  has_mask=True\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sample = torch_dataset[0]\n",
    "# torch_dataset2 = torch_dataset[:1000]\n",
    "print(sample)\n",
    "\n",
    "if sample.has_mask:\n",
    "    print(sample.mask)\n",
    "else:\n",
    "    print(\"Sample has no mask.\")\n",
    "\n",
    "if sample.has_transform:\n",
    "    print(sample.transform)\n",
    "else:\n",
    "    print(\"Sample has no transformation functions.\")\n",
    "    \n",
    "print(sample.pattern)\n",
    "print(\"==================   Or we can print patterns and shapes together   ==================\")\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StaticBatch(\n",
      "  input=(x=[b=5, t=6, n=207, f=1], edge_index=[2, e=2626], edge_weight=[e=2626]),\n",
      "  target=(y=[b=5, t=12, n=207, f=1]),\n",
      "  has_mask=True\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch = torch_dataset[:5]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data using mean and std computed over time and node dimensions\n",
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Train dataloader: size=27741}\n",
      "{Validation dataloader: size=3077}\n",
      "{Test dataloader: size=3425}\n",
      "{Predict dataloader: None}\n"
     ]
    }
   ],
   "source": [
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=val_len, test_len=test_len)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# print(dm)\n",
    "#%%\n",
    "dm.setup()\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = torch_dataset.n_channels   # 1 channel\n",
    "n_nodes = torch_dataset.n_nodes         # 207 nodes\n",
    "horizon = torch_dataset.horizon         # 12 time steps\n",
    "\n",
    "N = [n_nodes, M]\n",
    "K_list = list(np.array(N)-2)\n",
    "K_list = [205, M-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205, 4]\n",
      "evecs.shape:,  torch.Size([207, 205])\n",
      "evecs.shape:,  torch.Size([6, 4])\n",
      "evecs_kron.shape:,  torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "Graph_List = [nx.from_numpy_array(np.array(adj)), nx.path_graph(N[1])]\n",
    "\n",
    "evecs, evals, L_list = get_evcs_evals(Graph_List, K_list)\n",
    "\n",
    "\n",
    "for ii in range(len(evals)):\n",
    "    evals[ii] = evals[ii].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered constructor\n",
      "Warning: input_size (1) is less than 6. Adjusting to 6.\n",
      "CITRUS(\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=207, embedding_size=16)\n",
      "  (encoder): Linear(in_features=22, out_features=32, bias=True)\n",
      "  (CPGNN): CPGNN_ST_in_TTS(\n",
      "    (last_activation): ReLU()\n",
      "    (first_lin): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (last_lin): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (merge_lin): Linear(in_features=1242, out_features=1, bias=True)\n",
      "    (node_embeddings): NodeEmbedding(n_nodes=207, embedding_size=4)\n",
      "    (block_0): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(64, 64)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_1): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(64, 64)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_2): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(64, 64)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=48, out_features=72, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=12)\n",
      ")\n",
      "==============================================\n",
      "Number of model (CITRUS) parameters:    113505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_957743/2139055900.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  evecs=torch.tensor(evecs).to(device),\n"
     ]
    }
   ],
   "source": [
    "CGP_GNN = CITRUS(\n",
    "    input_size=input_size,\n",
    "    n_nodes=n_nodes,\n",
    "    horizon=horizon,\n",
    "    emb_size=emb_size,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    gnn_kernel=gnn_kernel,\n",
    "    mass=torch.ones(np.prod(N)).to(device),\n",
    "    evals=evals,\n",
    "    evecs=torch.tensor(evecs).to(device),\n",
    "    C_width=64,\n",
    "    N_block=3,\n",
    "    single_t=True,\n",
    "    use_gdc=[],\n",
    "    num_nodes=N,\n",
    "    last_activation=torch.nn.ReLU(),\n",
    "    mlp_hidden_dims=[64, 64, 64, 64],\n",
    "    dropout=False,\n",
    "    with_MLP=True,\n",
    "    diffusion_method='spectral',\n",
    "    device=device,\n",
    "    graph_wise=False\n",
    ")\n",
    "              \n",
    "print(CGP_GNN)\n",
    "print_model_size(CGP_GNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = MaskedMAE()\n",
    "\n",
    "metrics = {'mse': MaskedMSE(),\n",
    "           'mae': MaskedMAE(),\n",
    "           'mape': MaskedMAPE()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup predictor_CGP_GNN\n",
    "# setup predictor\n",
    "predictor_CGP_GNN = Predictor(\n",
    "    model=CGP_GNN,                   # our initialized model\n",
    "    optim_class=torch.optim.Adam,  # specify optimizer to be used...\n",
    "    optim_kwargs={'lr': lr},    # ...and parameters for its initialization\n",
    "    loss_fn=loss_fn,               # which loss function to be used\n",
    "    metrics=metrics,\n",
    "# metrics to be logged during train/val/test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_CGP_GNN = TensorBoardLogger(save_dir=\"FINAL_MetrLA_Github\", name=\"FINAL_MetrLA_Github\", version=0)\n",
    "\n",
    "checkpoint_callback_CGPGNN = ModelCheckpoint(\n",
    "    dirpath='FINAL_MetrLA_Github',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE        | 0      | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | CITRUS           | 113 K  | train\n",
      "-----------------------------------------------------------\n",
      "113 K     Trainable params\n",
      "0         Non-trainable params\n",
      "113 K     Total params\n",
      "0.454     Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only args ['x', 'edge_weight', 'edge_index'] are forwarded to the model (CITRUS).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2543616x17 and 22x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer_CGP_GNN \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39mn_epochs,\n\u001b[1;32m      2\u001b[0m                       logger\u001b[38;5;241m=\u001b[39mlogger_CGP_GNN,\n\u001b[1;32m      3\u001b[0m                       accelerator\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m                       callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_callback_CGPGNN],\n\u001b[1;32m      7\u001b[0m                       enable_progress_bar\u001b[38;5;241m=\u001b[39menable_progress_bar)\n\u001b[1;32m      9\u001b[0m t_CGPGNN \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer_CGP_GNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor_CGP_GNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_CGPGNN\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>> CGP-GNN training time, Elapsed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mround\u001b[39m(elapsed\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1054\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1054\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1056\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1083\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1080\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1083\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:145\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:437\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    431\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    436\u001b[0m )\n\u001b[0;32m--> 437\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    331\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/tsl/engines/predictor.py:366\u001b[0m, in \u001b[0;36mPredictor.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    363\u001b[0m mask \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Compute predictions\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m y_hat_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m y_hat_loss\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Scale target and output, eventually\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/tsl/engines/predictor.py:285\u001b[0m, in \u001b[0;36mPredictor.predict_batch\u001b[0;34m(self, batch, preprocess, postprocess, return_target, **forward_kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forward_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     forward_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 285\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Rescale outputs\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m postprocess:\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/tsl/engines/predictor.py:176\u001b[0m, in \u001b[0;36mPredictor.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_forward_kwargs:\n\u001b[1;32m    175\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_forward_kwargs(kwargs)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/m2ds/graph_ml/CITRUS-Graph_ML/MetrLA_PemsBay/layers.py:1229\u001b[0m, in \u001b[0;36mCITRUS.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m   1227\u001b[0m x_emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, emb], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m-> 1229\u001b[0m x_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_emb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# linear proj: x_enc = [x||emb]Θ + b  --> b t n f\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;66;03m# STMP\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;66;03m# h = self.time_nn(x_enc)  # temporal processing: x=[b t n f] -> h=[b n f]\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;66;03m# z = self.space_nn(h, edge_index, edge_weight)  # spatial processing --> b n f\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;66;03m# CPGNN\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCPGNN(x_enc) \u001b[38;5;66;03m# --> b n f\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ima/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2543616x17 and 22x32)"
     ]
    }
   ],
   "source": [
    "trainer_CGP_GNN = pl.Trainer(max_epochs=n_epochs,\n",
    "                      logger=logger_CGP_GNN,\n",
    "                      accelerator=device,\n",
    "                      devices=1, \n",
    "#                      limit_train_batches=train_batches,  # end an epoch after 100 updates\n",
    "                      callbacks=[checkpoint_callback_CGPGNN],\n",
    "                      enable_progress_bar=enable_progress_bar)\n",
    "\n",
    "t_CGPGNN = time.time()\n",
    "trainer_CGP_GNN.fit(predictor_CGP_GNN, datamodule=dm)\n",
    "elapsed = time.time() - t_CGPGNN\n",
    "print('>>>>>>>>>>>>>>>>>>>> CGP-GNN training time, Elapsed: %s' % round(elapsed/60,2), ' minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "predictor_CGP_GNN.load_model(checkpoint_callback_CGPGNN.best_model_path)\n",
    "predictor_CGP_GNN.freeze()\n",
    "\n",
    "CGP_GNN_results = trainer_CGP_GNN.test(predictor_CGP_GNN, datamodule=dm);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "elapsed = time.time() - t\n",
    "print('Elapsed: %s' % round(elapsed/60,2), ' minutes')\n",
    "print(600*'*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
