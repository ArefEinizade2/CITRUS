{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetrLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "import os\n",
    "import torch\n",
    "import tsl\n",
    "from tsl.metrics.torch import MaskedMSE, MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Molene')\n",
    "from layers import CITRUS\n",
    "\n",
    "import networkx as nx\n",
    "from Utilsss import get_evcs_evals\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from tsl.data import SpatioTemporalDataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsl.ops.connectivity import edge_index_to_adj\n",
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "from tsl.data.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_evec_evals(L_normalized_sparse_list, k_list):\n",
    "    evals, evecs = sparse.linalg.eigs(L_normalized_sparse_list[0], k=k_list[0], return_eigenvectors=True)\n",
    "    evals = torch.tensor(evals.real)\n",
    "    evals = evals.to(torch.float32)\n",
    "    evals_list = [evals]\n",
    "    evecs=torch.tensor(evecs.real).to(torch.float32)        \n",
    "    evecs_kron = evecs\n",
    "    \n",
    "    for p in range(1, len(L_normalized_sparse_list)):\n",
    "\n",
    "        evals, evecs = sparse.linalg.eigs(L_normalized_sparse_list[p], k=k_list[p], return_eigenvectors=True)\n",
    "        evals = torch.tensor(evals.real)\n",
    "        evals = evals.to(torch.float32)\n",
    "        evals_list.append(evals)\n",
    "        evecs = torch.tensor(evecs.real)        \n",
    "        evecs_kron = torch.kron(evecs_kron, evecs).to(torch.float32)\n",
    "    \n",
    "    return evals_list, evecs_kron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 6\n",
    "M_hat = M\n",
    "n_epochs = 300\n",
    "val_len = 0.1\n",
    "test_len = 0.1\n",
    "lr = 1e-2\n",
    "batch_size = 2048\n",
    "enable_progress_bar = True\n",
    "horizon = 12\n",
    "emb_size = 16    #@param\n",
    "hidden_size = 32   #@param\n",
    "rnn_layers = 1     #@param\n",
    "gnn_kernel = 2   #@param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = './MetrLA_Results/'\n",
    "\n",
    "if not os.path.isdir(destination_path):  \n",
    "    os.mkdir(destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"  PyG version: {torch_geometric.__version__}\")\n",
    "print(f\"  tsl version: {tsl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions ###############\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(edgeitems=3, precision=3)\n",
    "torch.set_printoptions(edgeitems=2, precision=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions ################\n",
    "def print_matrix(matrix):\n",
    "    return pd.DataFrame(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tsl.datasets import MetrLA\n",
    "\n",
    "dataset = MetrLA(root='./MetrLA')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(f\"Sampling period: {dataset.freq}\")\n",
    "print(f\"Has missing values: {dataset.has_mask}\")\n",
    "print(f\"Has exogenous variables: {dataset.has_covariates}\")\n",
    "print(f\"Covariates: {', '.join(dataset.covariates.keys())}\")\n",
    "\n",
    "print_matrix(dataset.dist)\n",
    "dataset.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(f\"Default similarity: {dataset.similarity_score}\")\n",
    "print(f\"Available similarity options: {dataset.similarity_options}\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "sim = dataset.get_similarity(\"distance\")  # or dataset.compute_similarity()\n",
    "\n",
    "print(\"Similarity matrix W:\")\n",
    "print_matrix(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "connectivity = dataset.get_connectivity(threshold=0.1,\n",
    "                                        include_self=False,\n",
    "                                        layout=\"edge_index\",\n",
    "                                        force_symmetric=True)\n",
    "\n",
    "edge_index, edge_weight = connectivity\n",
    "\n",
    "print(f'edge_index {edge_index.shape}:\\n', edge_index)\n",
    "print(f'edge_weight {edge_weight.shape}:\\n', edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tsl.ops.connectivity import edge_index_to_adj\n",
    "\n",
    "adj = edge_index_to_adj(edge_index, edge_weight)\n",
    "print(f'A {adj.shape}:')\n",
    "print_matrix(adj)\n",
    "print(f'Sparse edge weights:\\n', adj[edge_index[1], edge_index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "torch_dataset = SpatioTemporalDataset(target=dataset.dataframe(),\n",
    "                                      connectivity=connectivity,\n",
    "                                      mask=dataset.mask,\n",
    "                                      horizon=horizon,\n",
    "                                      window=M_hat,\n",
    "                                      stride=1)\n",
    "print(torch_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sample = torch_dataset[0]\n",
    "# torch_dataset2 = torch_dataset[:1000]\n",
    "print(sample)\n",
    "\n",
    "if sample.has_mask:\n",
    "    print(sample.mask)\n",
    "else:\n",
    "    print(\"Sample has no mask.\")\n",
    "\n",
    "if sample.has_transform:\n",
    "    print(sample.transform)\n",
    "else:\n",
    "    print(\"Sample has no transformation functions.\")\n",
    "    \n",
    "print(sample.pattern)\n",
    "print(\"==================   Or we can print patterns and shapes together   ==================\")\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "batch = torch_dataset[:5]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data using mean and std computed over time and node dimensions\n",
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=val_len, test_len=test_len)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# print(dm)\n",
    "#%%\n",
    "dm.setup()\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = torch_dataset.n_channels   # 1 channel\n",
    "n_nodes = torch_dataset.n_nodes         # 207 nodes\n",
    "horizon = torch_dataset.horizon         # 12 time steps\n",
    "\n",
    "N = [n_nodes, M]\n",
    "K_list = list(np.array(N)-2)\n",
    "K_list = [205, M-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "Graph_List = [nx.from_numpy_array(np.array(adj)), nx.path_graph(N[1])]\n",
    "\n",
    "evecs, evals, L_list = get_evcs_evals(Graph_List, K_list)\n",
    "\n",
    "\n",
    "for ii in range(len(evals)):\n",
    "    evals[ii] = evals[ii].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "CGP_GNN = CITRUS(\n",
    "    input_size=input_size,\n",
    "    n_nodes=n_nodes,\n",
    "    horizon=horizon,\n",
    "    emb_size=emb_size,\n",
    "    hidden_size=hidden_size,\n",
    "    rnn_layers=rnn_layers,\n",
    "    gnn_kernel=gnn_kernel,\n",
    "    mass=torch.ones(np.prod(N)).to(device),\n",
    "    evals=evals,\n",
    "    evecs=torch.tensor(evecs).to(device),\n",
    "    C_width=64,\n",
    "    N_block=3,\n",
    "    single_t=True,\n",
    "    use_gdc=[],\n",
    "    num_nodes=N,\n",
    "    last_activation=torch.nn.ReLU(),\n",
    "    mlp_hidden_dims=[64, 64, 64, 64],\n",
    "    dropout=False,\n",
    "    with_MLP=True,\n",
    "    diffusion_method='spectral',\n",
    "    device=device,\n",
    "    graph_wise=False\n",
    ")\n",
    "              \n",
    "print(CGP_GNN)\n",
    "print_model_size(CGP_GNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = MaskedMAE()\n",
    "\n",
    "metrics = {'mse': MaskedMSE(),\n",
    "           'mae': MaskedMAE(),\n",
    "           'mape': MaskedMAPE()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup predictor_CGP_GNN\n",
    "# setup predictor\n",
    "predictor_CGP_GNN = Predictor(\n",
    "    model=CGP_GNN,                   # our initialized model\n",
    "    optim_class=torch.optim.Adam,  # specify optimizer to be used...\n",
    "    optim_kwargs={'lr': lr},    # ...and parameters for its initialization\n",
    "    loss_fn=loss_fn,               # which loss function to be used\n",
    "    metrics=metrics,\n",
    "# metrics to be logged during train/val/test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_CGP_GNN = TensorBoardLogger(save_dir=\"FINAL_MetrLA_Github\", name=\"FINAL_MetrLA_Github\", version=0)\n",
    "\n",
    "checkpoint_callback_CGPGNN = ModelCheckpoint(\n",
    "    dirpath='FINAL_MetrLA_Github',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "trainer_CGP_GNN = pl.Trainer(max_epochs=n_epochs,\n",
    "                      logger=logger_CGP_GNN,\n",
    "                      accelerator=device,\n",
    "                      devices=1, \n",
    "#                      limit_train_batches=train_batches,  # end an epoch after 100 updates\n",
    "                      callbacks=[checkpoint_callback_CGPGNN],\n",
    "                      enable_progress_bar=enable_progress_bar)\n",
    "\n",
    "t_CGPGNN = time.time()\n",
    "trainer_CGP_GNN.fit(predictor_CGP_GNN, datamodule=dm)\n",
    "elapsed = time.time() - t_CGPGNN\n",
    "print('>>>>>>>>>>>>>>>>>>>> CGP-GNN training time, Elapsed: %s' % round(elapsed/60,2), ' minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "predictor_CGP_GNN.load_model(checkpoint_callback_CGPGNN.best_model_path)\n",
    "predictor_CGP_GNN.freeze()\n",
    "\n",
    "CGP_GNN_results = trainer_CGP_GNN.test(predictor_CGP_GNN, datamodule=dm);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "elapsed = time.time() - t\n",
    "print('Elapsed: %s' % round(elapsed/60,2), ' minutes')\n",
    "print(600*'*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
