{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from parametric_pooling_net_ordering import ParametricNetWithPoolingOrdered\n",
    "from difference_utils import perform_step_ahead_deltas, compute_iteration_rNMSE_with_deltas, \\\n",
    "    visualize_predictions, visualize_deltas\n",
    "from train_utils import train_model_regression\n",
    "from evaluation import MSELossWithSparsityRegularizer, rNMSELoss, compute_iteration_rNMSE\n",
    "from pred_utils import get_device, transform_data_to_all_steps_prediction, get_name_string, get_NOAA_dataset\n",
    "from misc_utils import check_create_folder\n",
    "from layers import CPGNN_ST, CPGNN_ST_v2, CPGNN_ST_v3, CITRUS, SGPModel\n",
    "import networkx as nx\n",
    "from Utilsss import get_evcs_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Device selected: cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "# np.random.seed(123)\n",
    "# random.seed(123)\n",
    "\n",
    "device = get_device(use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NOAA is selected\n",
      "\n",
      "\n",
      "\n",
      "Dataset path: ./dataset/processed/NOA_w=10_steps=[1, 2, 3, 4, 5]_splits=[0.35, 0.15, 0.5].pickle\n",
      "109 nodes - 10 observed timesteps - steps ahead: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "ds_folder = \"\"\n",
    "splits = [0.35, 0.15, 0.5]\n",
    "obs_window = 10\n",
    "DIFFERENCE = False\n",
    "\n",
    "data, steps_ahead, weighted_adjacency = get_NOAA_dataset(\n",
    "    ds_folder,\n",
    "    splits=splits,\n",
    "    obs_window=obs_window,\n",
    "    differenced=DIFFERENCE,\n",
    ")\n",
    "N_spatial_nodes = weighted_adjacency.shape[0]\n",
    "print(f\"{N_spatial_nodes} nodes - {obs_window} observed timesteps - steps ahead: {steps_ahead}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3051, 1, 109, 10]) torch.Size([1300, 1, 109, 10]) torch.Size([4366, 1, 109, 10])\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "trn_data, val_data, tst_data_deltas, trn_labels, val_labels, tst_labels_deltas = transform_data_to_all_steps_prediction(data, node_first=True, device=device)\n",
    "trn_data = trn_data.float()\n",
    "val_data = val_data.float()\n",
    "tst_data_deltas = tst_data_deltas.float()\n",
    "trn_labels = trn_labels.float()\n",
    "val_labels = val_labels.float()\n",
    "tst_labels_deltas = tst_labels_deltas.float()\n",
    "print(trn_data.shape, val_data.shape, tst_data_deltas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3051, 109]) torch.Size([1300, 109])\n"
     ]
    }
   ],
   "source": [
    "# obtain one-step labels for the training\n",
    "one_step_trn_labels = trn_labels[:, 0, :]  # [batch x step-ahead x nodes]\n",
    "one_step_val_labels = val_labels[:, 0, :]\n",
    "print(one_step_trn_labels.shape, one_step_val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERATIONS = 10\n",
    "num_epochs = 400\n",
    "learning_rate = 0.01# 0.0005\n",
    "weight_decay = 0.0025  # , 0.00001, 0]\n",
    "batch_size = 256  # 32\n",
    "patience = 100\n",
    "factor = 0.9\n",
    "\n",
    "not_learning_limit = 100\n",
    "lambda_value = 0  # 0.00025, 0.0005, 0.001, 0.005, 0.01, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTCNN\n",
    "n_nodes = weighted_adjacency.shape[0]\n",
    "M = obs_window\n",
    "N = [n_nodes, M]\n",
    "K_list = list(np.array(N)-2)\n",
    "# K_list = [2, 2]\n",
    "\n",
    "adj = weighted_adjacency\n",
    "Graph_List = [nx.from_numpy_array(np.array(adj)), nx.path_graph(obs_window)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107, 8]\n",
      "evecs.shape:,  torch.Size([109, 107])\n",
      "evecs.shape:,  torch.Size([10, 8])\n",
      "evecs_kron.shape:,  torch.Size([10, 8])\n"
     ]
    }
   ],
   "source": [
    "evecs, evals, L_list = get_evcs_evals(Graph_List, K_list)\n",
    "\n",
    "for ii in range(len(evals)):\n",
    "    evals[ii] = evals[ii].to(device)\n",
    "    \n",
    "dim = 4\n",
    "N_block = 3\n",
    "\n",
    "today = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "res_dict = {\n",
    "        'lr': learning_rate,\n",
    "        'results': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************************************************** iter: 0****************************************************************************************************\n",
      "CITRUS(\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "  (encoder): Linear(in_features=5, out_features=4, bias=True)\n",
      "  (CPGNN): CPGNN_ST_in_TTS(\n",
      "    (last_activation): LeakyReLU(negative_slope=0.01)\n",
      "    (first_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (last_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (merge_lin): Linear(in_features=1090, out_features=1, bias=True)\n",
      "    (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "    (block_0): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_1): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_2): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=1)\n",
      ")\n",
      "Number of parameters: 2544.0\n",
      "11 batches per epoch (3051 trn samples in total | batch_size: 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8616/2994952299.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  evecs = torch.tensor(evecs).to(device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      " Epoch 0\n",
      "\t train-loss: 140.436 | valid-loss: 375.205 \t| valid-metric: 1.02 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 1.02. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 1\n",
      "\t train-loss: 43.816 | valid-loss: 376.136 \t| valid-metric: 1.021 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 2\n",
      "\t train-loss: 25.792 | valid-loss: 374.598 \t| valid-metric: 1.019 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 1.019. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 3\n",
      "\t train-loss: 22.87 | valid-loss: 369.338 \t| valid-metric: 1.012 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 1.012. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 4\n",
      "\t train-loss: 21.156 | valid-loss: 362.148 \t| valid-metric: 1.002 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 1.002. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 5\n",
      "\t train-loss: 19.998 | valid-loss: 352.909 \t| valid-metric: 0.989 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.989. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 6\n",
      "\t train-loss: 18.956 | valid-loss: 340.314 \t| valid-metric: 0.971 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.971. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 7\n",
      "\t train-loss: 17.505 | valid-loss: 323.562 \t| valid-metric: 0.947 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.947. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 8\n",
      "\t train-loss: 15.729 | valid-loss: 302.112 \t| valid-metric: 0.915 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.915. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 9\n",
      "\t train-loss: 13.72 | valid-loss: 276.421 \t| valid-metric: 0.875 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.875. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 10\n",
      "\t train-loss: 11.668 | valid-loss: 248.411 \t| valid-metric: 0.83 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.83. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 11\n",
      "\t train-loss: 9.68 | valid-loss: 221.047 \t| valid-metric: 0.783 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.783. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 12\n",
      "\t train-loss: 8.008 | valid-loss: 194.931 \t| valid-metric: 0.735 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.735. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 13\n",
      "\t train-loss: 6.558 | valid-loss: 172.023 \t| valid-metric: 0.69 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.69. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 14\n",
      "\t train-loss: 5.471 | valid-loss: 151.681 \t| valid-metric: 0.648 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.648. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 15\n",
      "\t train-loss: 4.603 | valid-loss: 134.99 \t| valid-metric: 0.612 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.612. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 16\n",
      "\t train-loss: 3.977 | valid-loss: 121.191 \t| valid-metric: 0.58 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.58. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 17\n",
      "\t train-loss: 3.49 | valid-loss: 110.467 \t| valid-metric: 0.553 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.553. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 18\n",
      "\t train-loss: 3.099 | valid-loss: 101.684 \t| valid-metric: 0.531 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.531. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 19\n",
      "\t train-loss: 2.78 | valid-loss: 94.494 \t| valid-metric: 0.512 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.512. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 20\n",
      "\t train-loss: 2.514 | valid-loss: 88.295 \t| valid-metric: 0.495 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.495. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 21\n",
      "\t train-loss: 2.312 | valid-loss: 83.118 \t| valid-metric: 0.48 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.48. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 22\n",
      "\t train-loss: 2.166 | valid-loss: 79.328 \t| valid-metric: 0.469 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.469. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 23\n",
      "\t train-loss: 1.996 | valid-loss: 75.641 \t| valid-metric: 0.458 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.458. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 24\n",
      "\t train-loss: 1.874 | valid-loss: 73.066 \t| valid-metric: 0.45 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.45. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 25\n",
      "\t train-loss: 1.727 | valid-loss: 70.847 \t| valid-metric: 0.443 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.443. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 26\n",
      "\t train-loss: 1.666 | valid-loss: 68.589 \t| valid-metric: 0.436 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.436. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 27\n",
      "\t train-loss: 1.589 | valid-loss: 66.723 \t| valid-metric: 0.43 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.43. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 28\n",
      "\t train-loss: 1.507 | valid-loss: 64.812 \t| valid-metric: 0.424 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.424. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 29\n",
      "\t train-loss: 1.469 | valid-loss: 63.577 \t| valid-metric: 0.42 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.42. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 30\n",
      "\t train-loss: 1.426 | valid-loss: 62.14 \t| valid-metric: 0.415 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.415. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 31\n",
      "\t train-loss: 1.407 | valid-loss: 60.91 \t| valid-metric: 0.411 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.411. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 32\n",
      "\t train-loss: 1.369 | valid-loss: 59.747 \t| valid-metric: 0.407 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.407. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 33\n",
      "\t train-loss: 1.34 | valid-loss: 59.042 \t| valid-metric: 0.405 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.405. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 34\n",
      "\t train-loss: 1.307 | valid-loss: 58.354 \t| valid-metric: 0.402 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.402. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 35\n",
      "\t train-loss: 1.286 | valid-loss: 57.781 \t| valid-metric: 0.4 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.4. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 36\n",
      "\t train-loss: 1.264 | valid-loss: 57.129 \t| valid-metric: 0.398 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.398. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 37\n",
      "\t train-loss: 1.253 | valid-loss: 56.112 \t| valid-metric: 0.394 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.394. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 38\n",
      "\t train-loss: 1.254 | valid-loss: 55.85 \t| valid-metric: 0.393 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.393. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 39\n",
      "\t train-loss: 1.236 | valid-loss: 55.307 \t| valid-metric: 0.391 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.391. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 40\n",
      "\t train-loss: 1.218 | valid-loss: 55.117 \t| valid-metric: 0.391 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 41\n",
      "\t train-loss: 1.216 | valid-loss: 54.843 \t| valid-metric: 0.39 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.39. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 42\n",
      "\t train-loss: 1.204 | valid-loss: 54.282 \t| valid-metric: 0.388 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.388. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 43\n",
      "\t train-loss: 1.191 | valid-loss: 54.051 \t| valid-metric: 0.387 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.387. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 44\n",
      "\t train-loss: 1.185 | valid-loss: 53.74 \t| valid-metric: 0.386 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.386. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 45\n",
      "\t train-loss: 1.17 | valid-loss: 53.323 \t| valid-metric: 0.384 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.384. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 46\n",
      "\t train-loss: 1.19 | valid-loss: 53.388 \t| valid-metric: 0.385 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 47\n",
      "\t train-loss: 1.17 | valid-loss: 52.93 \t| valid-metric: 0.383 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.383. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 48\n",
      "\t train-loss: 1.185 | valid-loss: 52.776 \t| valid-metric: 0.382 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.382. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 49\n",
      "\t train-loss: 1.142 | valid-loss: 52.473 \t| valid-metric: 0.381 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.381. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 50\n",
      "\t train-loss: 1.145 | valid-loss: 52.535 \t| valid-metric: 0.382 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 51\n",
      "\t train-loss: 1.15 | valid-loss: 52.401 \t| valid-metric: 0.381 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 52\n",
      "\t train-loss: 1.18 | valid-loss: 51.931 \t| valid-metric: 0.379 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.379. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 53\n",
      "\t train-loss: 1.137 | valid-loss: 51.713 \t| valid-metric: 0.379 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 54\n",
      "\t train-loss: 1.142 | valid-loss: 51.79 \t| valid-metric: 0.379 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 55\n",
      "\t train-loss: 1.191 | valid-loss: 51.475 \t| valid-metric: 0.378 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.378. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 56\n",
      "\t train-loss: 1.126 | valid-loss: 51.722 \t| valid-metric: 0.379 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 57\n",
      "\t train-loss: 1.108 | valid-loss: 51.373 \t| valid-metric: 0.377 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.377. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 58\n",
      "\t train-loss: 1.118 | valid-loss: 51.169 \t| valid-metric: 0.377 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 59\n",
      "\t train-loss: 1.133 | valid-loss: 51.356 \t| valid-metric: 0.377 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 60\n",
      "\t train-loss: 1.093 | valid-loss: 51.008 \t| valid-metric: 0.376 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.376. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 61\n",
      "\t train-loss: 1.09 | valid-loss: 51.005 \t| valid-metric: 0.376 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 62\n",
      "\t train-loss: 1.08 | valid-loss: 50.678 \t| valid-metric: 0.375 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.375. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 63\n",
      "\t train-loss: 1.071 | valid-loss: 50.294 \t| valid-metric: 0.373 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.373. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 64\n",
      "\t train-loss: 1.075 | valid-loss: 50.054 \t| valid-metric: 0.372 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.372. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 65\n",
      "\t train-loss: 1.056 | valid-loss: 50.093 \t| valid-metric: 0.373 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 66\n",
      "\t train-loss: 1.056 | valid-loss: 49.832 \t| valid-metric: 0.372 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 67\n",
      "\t train-loss: 1.058 | valid-loss: 49.895 \t| valid-metric: 0.372 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 68\n",
      "\t train-loss: 1.059 | valid-loss: 49.732 \t| valid-metric: 0.371 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.371. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 69\n",
      "\t train-loss: 1.144 | valid-loss: 49.721 \t| valid-metric: 0.371 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 70\n",
      "\t train-loss: 1.077 | valid-loss: 50.053 \t| valid-metric: 0.372 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 71\n",
      "\t train-loss: 1.047 | valid-loss: 49.476 \t| valid-metric: 0.37 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.37. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 72\n",
      "\t train-loss: 1.024 | valid-loss: 49.321 \t| valid-metric: 0.37 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 73\n",
      "\t train-loss: 1.031 | valid-loss: 48.731 \t| valid-metric: 0.367 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.367. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 74\n",
      "\t train-loss: 1.01 | valid-loss: 49.084 \t| valid-metric: 0.369 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 75\n",
      "\t train-loss: 1.016 | valid-loss: 48.754 \t| valid-metric: 0.368 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 76\n",
      "\t train-loss: 1.014 | valid-loss: 48.507 \t| valid-metric: 0.367 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 77\n",
      "\t train-loss: 1.027 | valid-loss: 48.878 \t| valid-metric: 0.368 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 78\n",
      "\t train-loss: 1.057 | valid-loss: 48.723 \t| valid-metric: 0.367 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 79\n",
      "\t train-loss: 1.001 | valid-loss: 48.49 \t| valid-metric: 0.367 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 80\n",
      "\t train-loss: 1.008 | valid-loss: 48.297 \t| valid-metric: 0.366 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.366. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 81\n",
      "\t train-loss: 0.98 | valid-loss: 48.172 \t| valid-metric: 0.365 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.365. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 82\n",
      "\t train-loss: 1.018 | valid-loss: 47.786 \t| valid-metric: 0.364 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.364. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 83\n",
      "\t train-loss: 1.024 | valid-loss: 48.185 \t| valid-metric: 0.365 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 84\n",
      "\t train-loss: 0.989 | valid-loss: 47.918 \t| valid-metric: 0.364 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 85\n",
      "\t train-loss: 0.994 | valid-loss: 47.911 \t| valid-metric: 0.364 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 86\n",
      "\t train-loss: 1.017 | valid-loss: 47.795 \t| valid-metric: 0.364 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 87\n",
      "\t train-loss: 0.977 | valid-loss: 47.644 \t| valid-metric: 0.363 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.363. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 88\n",
      "\t train-loss: 0.95 | valid-loss: 47.358 \t| valid-metric: 0.362 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.362. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 89\n",
      "\t train-loss: 0.959 | valid-loss: 47.091 \t| valid-metric: 0.361 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.361. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 90\n",
      "\t train-loss: 1.004 | valid-loss: 46.762 \t| valid-metric: 0.36 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.36. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 91\n",
      "\t train-loss: 1.002 | valid-loss: 47.348 \t| valid-metric: 0.362 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 92\n",
      "\t train-loss: 0.932 | valid-loss: 47.462 \t| valid-metric: 0.363 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 93\n",
      "\t train-loss: 0.958 | valid-loss: 47.008 \t| valid-metric: 0.361 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 94\n",
      "\t train-loss: 0.957 | valid-loss: 46.324 \t| valid-metric: 0.358 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.358. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 95\n",
      "\t train-loss: 0.942 | valid-loss: 46.554 \t| valid-metric: 0.359 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 96\n",
      "\t train-loss: 0.924 | valid-loss: 46.56 \t| valid-metric: 0.359 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 97\n",
      "\t train-loss: 0.924 | valid-loss: 46.634 \t| valid-metric: 0.359 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 98\n",
      "\t train-loss: 0.91 | valid-loss: 46.684 \t| valid-metric: 0.36 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 99\n",
      "\t train-loss: 0.954 | valid-loss: 46.197 \t| valid-metric: 0.358 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 100\n",
      "\t train-loss: 0.928 | valid-loss: 46.312 \t| valid-metric: 0.358 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 101\n",
      "\t train-loss: 0.922 | valid-loss: 46.376 \t| valid-metric: 0.358 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 102\n",
      "\t train-loss: 0.968 | valid-loss: 46.297 \t| valid-metric: 0.358 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 103\n",
      "\t train-loss: 0.921 | valid-loss: 45.935 \t| valid-metric: 0.357 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.357. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 104\n",
      "\t train-loss: 0.91 | valid-loss: 46.253 \t| valid-metric: 0.358 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 105\n",
      "\t train-loss: 0.914 | valid-loss: 45.881 \t| valid-metric: 0.357 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 106\n",
      "\t train-loss: 0.875 | valid-loss: 45.529 \t| valid-metric: 0.355 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.355. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 107\n",
      "\t train-loss: 0.934 | valid-loss: 44.944 \t| valid-metric: 0.353 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.353. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 108\n",
      "\t train-loss: 0.989 | valid-loss: 45.624 \t| valid-metric: 0.356 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 109\n",
      "\t train-loss: 0.949 | valid-loss: 45.687 \t| valid-metric: 0.356 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 110\n",
      "\t train-loss: 0.992 | valid-loss: 46.246 \t| valid-metric: 0.358 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 111\n",
      "\t train-loss: 1.037 | valid-loss: 46.254 \t| valid-metric: 0.358 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 112\n",
      "\t train-loss: 0.989 | valid-loss: 46.428 \t| valid-metric: 0.359 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 113\n",
      "\t train-loss: 0.955 | valid-loss: 46.448 \t| valid-metric: 0.359 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 114\n",
      "\t train-loss: 0.915 | valid-loss: 45.907 \t| valid-metric: 0.357 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 115\n",
      "\t train-loss: 0.887 | valid-loss: 45.958 \t| valid-metric: 0.357 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 116\n",
      "\t train-loss: 0.896 | valid-loss: 45.664 \t| valid-metric: 0.356 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 117\n",
      "\t train-loss: 0.841 | valid-loss: 44.984 \t| valid-metric: 0.353 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 118\n",
      "\t train-loss: 0.845 | valid-loss: 44.599 \t| valid-metric: 0.352 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.352. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 119\n",
      "\t train-loss: 0.854 | valid-loss: 44.735 \t| valid-metric: 0.352 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 120\n",
      "\t train-loss: 0.823 | valid-loss: 44.76 \t| valid-metric: 0.352 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 121\n",
      "\t train-loss: 0.818 | valid-loss: 44.567 \t| valid-metric: 0.351 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.351. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 122\n",
      "\t train-loss: 0.816 | valid-loss: 44.271 \t| valid-metric: 0.35 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.35. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 123\n",
      "\t train-loss: 0.83 | valid-loss: 43.955 \t| valid-metric: 0.349 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.349. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 124\n",
      "\t train-loss: 0.842 | valid-loss: 44.254 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 125\n",
      "\t train-loss: 0.834 | valid-loss: 44.62 \t| valid-metric: 0.352 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 126\n",
      "\t train-loss: 0.85 | valid-loss: 44.288 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 127\n",
      "\t train-loss: 0.871 | valid-loss: 44.522 \t| valid-metric: 0.351 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 128\n",
      "\t train-loss: 0.893 | valid-loss: 45.102 \t| valid-metric: 0.354 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 129\n",
      "\t train-loss: 0.87 | valid-loss: 44.217 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 130\n",
      "\t train-loss: 0.83 | valid-loss: 44.133 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 131\n",
      "\t train-loss: 0.907 | valid-loss: 44.302 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 132\n",
      "\t train-loss: 0.865 | valid-loss: 44.048 \t| valid-metric: 0.349 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 133\n",
      "\t train-loss: 0.824 | valid-loss: 44.613 \t| valid-metric: 0.352 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 134\n",
      "\t train-loss: 0.801 | valid-loss: 44.414 \t| valid-metric: 0.351 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 135\n",
      "\t train-loss: 0.791 | valid-loss: 43.799 \t| valid-metric: 0.348 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.348. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 136\n",
      "\t train-loss: 0.817 | valid-loss: 43.628 \t| valid-metric: 0.348 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 137\n",
      "\t train-loss: 0.802 | valid-loss: 43.745 \t| valid-metric: 0.348 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 138\n",
      "\t train-loss: 0.861 | valid-loss: 43.798 \t| valid-metric: 0.348 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 139\n",
      "\t train-loss: 0.87 | valid-loss: 44.146 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 140\n",
      "\t train-loss: 0.835 | valid-loss: 44.123 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 141\n",
      "\t train-loss: 0.783 | valid-loss: 44.291 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 142\n",
      "\t train-loss: 0.792 | valid-loss: 43.922 \t| valid-metric: 0.349 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 143\n",
      "\t train-loss: 0.802 | valid-loss: 43.623 \t| valid-metric: 0.348 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 144\n",
      "\t train-loss: 0.768 | valid-loss: 43.728 \t| valid-metric: 0.348 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 145\n",
      "\t train-loss: 0.855 | valid-loss: 44.132 \t| valid-metric: 0.35 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 146\n",
      "\t train-loss: 0.819 | valid-loss: 43.535 \t| valid-metric: 0.347 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.347. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 147\n",
      "\t train-loss: 0.796 | valid-loss: 43.289 \t| valid-metric: 0.346 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.346. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 148\n",
      "\t train-loss: 0.775 | valid-loss: 43.956 \t| valid-metric: 0.349 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 149\n",
      "\t train-loss: 0.738 | valid-loss: 43.261 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 150\n",
      "\t train-loss: 0.728 | valid-loss: 42.349 \t| valid-metric: 0.343 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.343. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 151\n",
      "\t train-loss: 0.745 | valid-loss: 42.854 \t| valid-metric: 0.345 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 152\n",
      "\t train-loss: 0.765 | valid-loss: 43.013 \t| valid-metric: 0.345 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 153\n",
      "\t train-loss: 0.83 | valid-loss: 43.27 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 154\n",
      "\t train-loss: 0.763 | valid-loss: 42.848 \t| valid-metric: 0.345 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 155\n",
      "\t train-loss: 0.824 | valid-loss: 43.117 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 156\n",
      "\t train-loss: 0.747 | valid-loss: 43.101 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 157\n",
      "\t train-loss: 0.716 | valid-loss: 42.713 \t| valid-metric: 0.344 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 158\n",
      "\t train-loss: 0.738 | valid-loss: 42.179 \t| valid-metric: 0.342 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.342. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 159\n",
      "\t train-loss: 0.725 | valid-loss: 42.566 \t| valid-metric: 0.343 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 160\n",
      "\t train-loss: 0.777 | valid-loss: 43.067 \t| valid-metric: 0.345 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 161\n",
      "\t train-loss: 0.796 | valid-loss: 43.27 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 162\n",
      "\t train-loss: 0.783 | valid-loss: 43.423 \t| valid-metric: 0.347 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 163\n",
      "\t train-loss: 0.696 | valid-loss: 42.511 \t| valid-metric: 0.343 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 164\n",
      "\t train-loss: 0.769 | valid-loss: 42.296 \t| valid-metric: 0.342 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 165\n",
      "\t train-loss: 0.836 | valid-loss: 42.773 \t| valid-metric: 0.344 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 166\n",
      "\t train-loss: 0.749 | valid-loss: 43.285 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 167\n",
      "\t train-loss: 0.715 | valid-loss: 43.145 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 168\n",
      "\t train-loss: 0.694 | valid-loss: 42.741 \t| valid-metric: 0.344 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 169\n",
      "\t train-loss: 0.699 | valid-loss: 41.771 \t| valid-metric: 0.34 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.34. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 170\n",
      "\t train-loss: 0.739 | valid-loss: 42.166 \t| valid-metric: 0.342 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 171\n",
      "\t train-loss: 0.724 | valid-loss: 41.818 \t| valid-metric: 0.34 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 172\n",
      "\t train-loss: 0.696 | valid-loss: 41.941 \t| valid-metric: 0.341 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 173\n",
      "\t train-loss: 0.688 | valid-loss: 42.161 \t| valid-metric: 0.342 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 174\n",
      "\t train-loss: 0.68 | valid-loss: 41.933 \t| valid-metric: 0.341 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 175\n",
      "\t train-loss: 0.669 | valid-loss: 41.555 \t| valid-metric: 0.339 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.339. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 176\n",
      "\t train-loss: 0.669 | valid-loss: 41.525 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 177\n",
      "\t train-loss: 0.66 | valid-loss: 41.21 \t| valid-metric: 0.338 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.338. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 178\n",
      "\t train-loss: 0.691 | valid-loss: 41.725 \t| valid-metric: 0.34 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 179\n",
      "\t train-loss: 0.694 | valid-loss: 42.231 \t| valid-metric: 0.342 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 180\n",
      "\t train-loss: 0.678 | valid-loss: 41.565 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 181\n",
      "\t train-loss: 0.709 | valid-loss: 41.693 \t| valid-metric: 0.34 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 182\n",
      "\t train-loss: 0.686 | valid-loss: 41.757 \t| valid-metric: 0.34 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 183\n",
      "\t train-loss: 0.751 | valid-loss: 41.796 \t| valid-metric: 0.34 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 184\n",
      "\t train-loss: 0.687 | valid-loss: 42.075 \t| valid-metric: 0.341 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 185\n",
      "\t train-loss: 0.664 | valid-loss: 42.146 \t| valid-metric: 0.342 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 186\n",
      "\t train-loss: 0.663 | valid-loss: 41.327 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 187\n",
      "\t train-loss: 0.688 | valid-loss: 41.775 \t| valid-metric: 0.34 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 188\n",
      "\t train-loss: 0.645 | valid-loss: 41.238 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 189\n",
      "\t train-loss: 0.641 | valid-loss: 40.917 \t| valid-metric: 0.337 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.337. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 190\n",
      "\t train-loss: 0.644 | valid-loss: 40.663 \t| valid-metric: 0.336 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.336. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 191\n",
      "\t train-loss: 0.684 | valid-loss: 41.351 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 192\n",
      "\t train-loss: 0.69 | valid-loss: 41.194 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 193\n",
      "\t train-loss: 0.674 | valid-loss: 42.24 \t| valid-metric: 0.342 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 194\n",
      "\t train-loss: 0.678 | valid-loss: 41.487 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 195\n",
      "\t train-loss: 0.649 | valid-loss: 41.135 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 196\n",
      "\t train-loss: 0.655 | valid-loss: 41.031 \t| valid-metric: 0.337 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 197\n",
      "\t train-loss: 0.639 | valid-loss: 41.219 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 198\n",
      "\t train-loss: 0.715 | valid-loss: 41.541 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 199\n",
      "\t train-loss: 0.653 | valid-loss: 41.589 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 200\n",
      "\t train-loss: 0.632 | valid-loss: 40.939 \t| valid-metric: 0.337 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 201\n",
      "\t train-loss: 0.617 | valid-loss: 41.141 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 202\n",
      "\t train-loss: 0.677 | valid-loss: 41.393 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 203\n",
      "\t train-loss: 0.656 | valid-loss: 40.775 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 204\n",
      "\t train-loss: 0.685 | valid-loss: 41.367 \t| valid-metric: 0.339 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 205\n",
      "\t train-loss: 0.621 | valid-loss: 40.918 \t| valid-metric: 0.337 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 206\n",
      "\t train-loss: 0.618 | valid-loss: 40.807 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 207\n",
      "\t train-loss: 0.638 | valid-loss: 41.312 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 208\n",
      "\t train-loss: 0.647 | valid-loss: 40.71 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 209\n",
      "\t train-loss: 0.61 | valid-loss: 40.619 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 210\n",
      "\t train-loss: 0.631 | valid-loss: 40.872 \t| valid-metric: 0.337 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 211\n",
      "\t train-loss: 0.648 | valid-loss: 40.604 \t| valid-metric: 0.335 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.335. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 212\n",
      "\t train-loss: 0.625 | valid-loss: 40.79 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 213\n",
      "\t train-loss: 0.635 | valid-loss: 40.965 \t| valid-metric: 0.337 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 214\n",
      "\t train-loss: 0.654 | valid-loss: 41.283 \t| valid-metric: 0.338 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 215\n",
      "\t train-loss: 0.632 | valid-loss: 40.801 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 216\n",
      "\t train-loss: 0.626 | valid-loss: 40.851 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 217\n",
      "\t train-loss: 0.628 | valid-loss: 40.747 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 218\n",
      "\t train-loss: 0.677 | valid-loss: 40.805 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 219\n",
      "\t train-loss: 0.62 | valid-loss: 40.727 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 220\n",
      "\t train-loss: 0.595 | valid-loss: 40.739 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 221\n",
      "\t train-loss: 0.635 | valid-loss: 40.678 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 222\n",
      "\t train-loss: 0.637 | valid-loss: 41.047 \t| valid-metric: 0.337 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 223\n",
      "\t train-loss: 0.621 | valid-loss: 40.467 \t| valid-metric: 0.335 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 224\n",
      "\t train-loss: 0.582 | valid-loss: 40.196 \t| valid-metric: 0.334 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.334. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 225\n",
      "\t train-loss: 0.579 | valid-loss: 39.508 \t| valid-metric: 0.331 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.331. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 226\n",
      "\t train-loss: 0.578 | valid-loss: 40.099 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 227\n",
      "\t train-loss: 0.581 | valid-loss: 39.915 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 228\n",
      "\t train-loss: 0.584 | valid-loss: 40.337 \t| valid-metric: 0.334 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 229\n",
      "\t train-loss: 0.589 | valid-loss: 40.339 \t| valid-metric: 0.334 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 230\n",
      "\t train-loss: 0.574 | valid-loss: 39.747 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 231\n",
      "\t train-loss: 0.574 | valid-loss: 39.837 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 232\n",
      "\t train-loss: 0.57 | valid-loss: 39.648 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 233\n",
      "\t train-loss: 0.582 | valid-loss: 40.268 \t| valid-metric: 0.334 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 234\n",
      "\t train-loss: 0.591 | valid-loss: 40.112 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 235\n",
      "\t train-loss: 0.581 | valid-loss: 40.11 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 236\n",
      "\t train-loss: 0.587 | valid-loss: 40.096 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 237\n",
      "\t train-loss: 0.604 | valid-loss: 40.403 \t| valid-metric: 0.335 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 238\n",
      "\t train-loss: 0.598 | valid-loss: 39.755 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 239\n",
      "\t train-loss: 0.579 | valid-loss: 39.975 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 240\n",
      "\t train-loss: 0.558 | valid-loss: 39.756 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 241\n",
      "\t train-loss: 0.562 | valid-loss: 39.556 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 242\n",
      "\t train-loss: 0.558 | valid-loss: 39.503 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 243\n",
      "\t train-loss: 0.585 | valid-loss: 39.951 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 244\n",
      "\t train-loss: 0.623 | valid-loss: 40.094 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 245\n",
      "\t train-loss: 0.68 | valid-loss: 40.264 \t| valid-metric: 0.334 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 246\n",
      "\t train-loss: 0.652 | valid-loss: 40.445 \t| valid-metric: 0.335 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 247\n",
      "\t train-loss: 0.61 | valid-loss: 40.727 \t| valid-metric: 0.336 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 248\n",
      "\t train-loss: 0.595 | valid-loss: 40.399 \t| valid-metric: 0.335 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 249\n",
      "\t train-loss: 0.606 | valid-loss: 40.13 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 250\n",
      "\t train-loss: 0.594 | valid-loss: 39.964 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 251\n",
      "\t train-loss: 0.551 | valid-loss: 39.744 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 252\n",
      "\t train-loss: 0.545 | valid-loss: 40.042 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 253\n",
      "\t train-loss: 0.55 | valid-loss: 38.985 \t| valid-metric: 0.329 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.329. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 254\n",
      "\t train-loss: 0.579 | valid-loss: 38.612 \t| valid-metric: 0.327 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.327. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 255\n",
      "\t train-loss: 0.615 | valid-loss: 40.05 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 256\n",
      "\t train-loss: 0.642 | valid-loss: 40.434 \t| valid-metric: 0.335 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 257\n",
      "\t train-loss: 0.569 | valid-loss: 39.959 \t| valid-metric: 0.333 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 258\n",
      "\t train-loss: 0.557 | valid-loss: 39.485 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 259\n",
      "\t train-loss: 0.543 | valid-loss: 39.282 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 260\n",
      "\t train-loss: 0.584 | valid-loss: 39.76 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 261\n",
      "\t train-loss: 0.564 | valid-loss: 39.785 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 262\n",
      "\t train-loss: 0.58 | valid-loss: 39.268 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 263\n",
      "\t train-loss: 0.57 | valid-loss: 39.557 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 264\n",
      "\t train-loss: 0.545 | valid-loss: 38.982 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 265\n",
      "\t train-loss: 0.537 | valid-loss: 39.37 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 266\n",
      "\t train-loss: 0.529 | valid-loss: 39.429 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 267\n",
      "\t train-loss: 0.548 | valid-loss: 39.587 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 268\n",
      "\t train-loss: 0.556 | valid-loss: 39.224 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 269\n",
      "\t train-loss: 0.585 | valid-loss: 39.281 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 270\n",
      "\t train-loss: 0.565 | valid-loss: 39.715 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 271\n",
      "\t train-loss: 0.568 | valid-loss: 39.609 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 272\n",
      "\t train-loss: 0.561 | valid-loss: 39.233 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 273\n",
      "\t train-loss: 0.596 | valid-loss: 39.421 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 274\n",
      "\t train-loss: 0.547 | valid-loss: 39.599 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 275\n",
      "\t train-loss: 0.543 | valid-loss: 39.786 \t| valid-metric: 0.332 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 276\n",
      "\t train-loss: 0.588 | valid-loss: 39.127 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 277\n",
      "\t train-loss: 0.546 | valid-loss: 39.495 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 278\n",
      "\t train-loss: 0.539 | valid-loss: 38.849 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 279\n",
      "\t train-loss: 0.559 | valid-loss: 39.45 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 280\n",
      "\t train-loss: 0.555 | valid-loss: 38.512 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 281\n",
      "\t train-loss: 0.521 | valid-loss: 38.832 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 282\n",
      "\t train-loss: 0.524 | valid-loss: 38.665 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 283\n",
      "\t train-loss: 0.519 | valid-loss: 38.89 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 284\n",
      "\t train-loss: 0.54 | valid-loss: 38.899 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 285\n",
      "\t train-loss: 0.586 | valid-loss: 39.635 \t| valid-metric: 0.331 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 286\n",
      "\t train-loss: 0.611 | valid-loss: 39.189 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 287\n",
      "\t train-loss: 0.538 | valid-loss: 39.193 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 288\n",
      "\t train-loss: 0.516 | valid-loss: 39.024 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 289\n",
      "\t train-loss: 0.53 | valid-loss: 38.882 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 290\n",
      "\t train-loss: 0.522 | valid-loss: 38.389 \t| valid-metric: 0.326 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.326. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 291\n",
      "\t train-loss: 0.579 | valid-loss: 39.037 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 292\n",
      "\t train-loss: 0.55 | valid-loss: 39.319 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 293\n",
      "\t train-loss: 0.523 | valid-loss: 38.938 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 294\n",
      "\t train-loss: 0.509 | valid-loss: 38.823 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 295\n",
      "\t train-loss: 0.526 | valid-loss: 38.602 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 296\n",
      "\t train-loss: 0.524 | valid-loss: 38.468 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 297\n",
      "\t train-loss: 0.523 | valid-loss: 38.703 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 298\n",
      "\t train-loss: 0.549 | valid-loss: 38.834 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 299\n",
      "\t train-loss: 0.58 | valid-loss: 38.558 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 300\n",
      "\t train-loss: 0.673 | valid-loss: 40.162 \t| valid-metric: 0.334 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 301\n",
      "\t train-loss: 0.569 | valid-loss: 40.165 \t| valid-metric: 0.334 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 302\n",
      "\t train-loss: 0.515 | valid-loss: 39.235 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 303\n",
      "\t train-loss: 0.559 | valid-loss: 38.531 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 304\n",
      "\t train-loss: 0.555 | valid-loss: 38.547 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 305\n",
      "\t train-loss: 0.526 | valid-loss: 38.812 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 306\n",
      "\t train-loss: 0.498 | valid-loss: 38.114 \t| valid-metric: 0.325 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.325. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 307\n",
      "\t train-loss: 0.498 | valid-loss: 38.174 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 308\n",
      "\t train-loss: 0.532 | valid-loss: 38.521 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 309\n",
      "\t train-loss: 0.52 | valid-loss: 38.611 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 310\n",
      "\t train-loss: 0.505 | valid-loss: 38.349 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 311\n",
      "\t train-loss: 0.516 | valid-loss: 38.347 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 312\n",
      "\t train-loss: 0.494 | valid-loss: 38.32 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 313\n",
      "\t train-loss: 0.5 | valid-loss: 37.985 \t| valid-metric: 0.324 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.324. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 314\n",
      "\t train-loss: 0.496 | valid-loss: 37.682 \t| valid-metric: 0.323 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.323. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 315\n",
      "\t train-loss: 0.498 | valid-loss: 38.257 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 316\n",
      "\t train-loss: 0.501 | valid-loss: 38.064 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 317\n",
      "\t train-loss: 0.605 | valid-loss: 39.086 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 318\n",
      "\t train-loss: 0.532 | valid-loss: 39.275 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 319\n",
      "\t train-loss: 0.53 | valid-loss: 38.59 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 320\n",
      "\t train-loss: 0.562 | valid-loss: 39.107 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 321\n",
      "\t train-loss: 0.523 | valid-loss: 38.425 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 322\n",
      "\t train-loss: 0.545 | valid-loss: 38.641 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 323\n",
      "\t train-loss: 0.51 | valid-loss: 38.29 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 324\n",
      "\t train-loss: 0.524 | valid-loss: 38.689 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 325\n",
      "\t train-loss: 0.519 | valid-loss: 38.495 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 326\n",
      "\t train-loss: 0.517 | valid-loss: 38.112 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 327\n",
      "\t train-loss: 0.594 | valid-loss: 38.376 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 328\n",
      "\t train-loss: 0.617 | valid-loss: 39.222 \t| valid-metric: 0.33 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 329\n",
      "\t train-loss: 0.567 | valid-loss: 39.046 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 330\n",
      "\t train-loss: 0.552 | valid-loss: 38.901 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 331\n",
      "\t train-loss: 0.538 | valid-loss: 38.73 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 332\n",
      "\t train-loss: 0.572 | valid-loss: 39.07 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 333\n",
      "\t train-loss: 0.496 | valid-loss: 38.983 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 334\n",
      "\t train-loss: 0.484 | valid-loss: 37.787 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 335\n",
      "\t train-loss: 0.489 | valid-loss: 37.565 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 336\n",
      "\t train-loss: 0.507 | valid-loss: 38.024 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 337\n",
      "\t train-loss: 0.493 | valid-loss: 38.395 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 338\n",
      "\t train-loss: 0.493 | valid-loss: 37.862 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 339\n",
      "\t train-loss: 0.483 | valid-loss: 37.359 \t| valid-metric: 0.322 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.322. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 340\n",
      "\t train-loss: 0.478 | valid-loss: 37.845 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 341\n",
      "\t train-loss: 0.501 | valid-loss: 38.284 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 342\n",
      "\t train-loss: 0.485 | valid-loss: 37.83 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 343\n",
      "\t train-loss: 0.504 | valid-loss: 37.713 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 344\n",
      "\t train-loss: 0.49 | valid-loss: 38.101 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 345\n",
      "\t train-loss: 0.517 | valid-loss: 38.078 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 346\n",
      "\t train-loss: 0.499 | valid-loss: 37.89 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 347\n",
      "\t train-loss: 0.518 | valid-loss: 37.951 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 348\n",
      "\t train-loss: 0.484 | valid-loss: 38.089 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 349\n",
      "\t train-loss: 0.491 | valid-loss: 37.372 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 350\n",
      "\t train-loss: 0.488 | valid-loss: 37.673 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 351\n",
      "\t train-loss: 0.513 | valid-loss: 37.913 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 352\n",
      "\t train-loss: 0.571 | valid-loss: 38.07 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 353\n",
      "\t train-loss: 0.524 | valid-loss: 39.026 \t| valid-metric: 0.329 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 354\n",
      "\t train-loss: 0.494 | valid-loss: 38.537 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 355\n",
      "\t train-loss: 0.481 | valid-loss: 37.101 \t| valid-metric: 0.321 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.321. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 356\n",
      "\t train-loss: 0.498 | valid-loss: 37.409 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 357\n",
      "\t train-loss: 0.528 | valid-loss: 38.155 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 358\n",
      "\t train-loss: 0.504 | valid-loss: 38.085 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 359\n",
      "\t train-loss: 0.488 | valid-loss: 37.852 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 360\n",
      "\t train-loss: 0.498 | valid-loss: 37.538 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 361\n",
      "\t train-loss: 0.505 | valid-loss: 37.668 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 362\n",
      "\t train-loss: 0.495 | valid-loss: 38.075 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 363\n",
      "\t train-loss: 0.53 | valid-loss: 37.518 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 364\n",
      "\t train-loss: 0.515 | valid-loss: 38.789 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 365\n",
      "\t train-loss: 0.478 | valid-loss: 37.623 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 366\n",
      "\t train-loss: 0.488 | valid-loss: 37.422 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 367\n",
      "\t train-loss: 0.485 | valid-loss: 37.487 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 368\n",
      "\t train-loss: 0.478 | valid-loss: 36.938 \t| valid-metric: 0.32 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.32. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 369\n",
      "\t train-loss: 0.492 | valid-loss: 37.309 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 370\n",
      "\t train-loss: 0.514 | valid-loss: 37.404 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 371\n",
      "\t train-loss: 0.495 | valid-loss: 38.038 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 372\n",
      "\t train-loss: 0.504 | valid-loss: 37.317 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 373\n",
      "\t train-loss: 0.519 | valid-loss: 38.597 \t| valid-metric: 0.327 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 374\n",
      "\t train-loss: 0.532 | valid-loss: 38.125 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 375\n",
      "\t train-loss: 0.486 | valid-loss: 37.886 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 376\n",
      "\t train-loss: 0.514 | valid-loss: 37.939 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 377\n",
      "\t train-loss: 0.509 | valid-loss: 37.686 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 378\n",
      "\t train-loss: 0.52 | valid-loss: 37.81 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 379\n",
      "\t train-loss: 0.5 | valid-loss: 37.901 \t| valid-metric: 0.324 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 380\n",
      "\t train-loss: 0.499 | valid-loss: 37.475 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 381\n",
      "\t train-loss: 0.466 | valid-loss: 37.204 \t| valid-metric: 0.321 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 382\n",
      "\t train-loss: 0.522 | valid-loss: 38.001 \t| valid-metric: 0.325 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 383\n",
      "\t train-loss: 0.529 | valid-loss: 38.749 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 384\n",
      "\t train-loss: 0.475 | valid-loss: 37.526 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 385\n",
      "\t train-loss: 0.467 | valid-loss: 37.34 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 386\n",
      "\t train-loss: 0.467 | valid-loss: 36.907 \t| valid-metric: 0.32 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 387\n",
      "\t train-loss: 0.5 | valid-loss: 37.185 \t| valid-metric: 0.321 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 388\n",
      "\t train-loss: 0.512 | valid-loss: 37.531 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 389\n",
      "\t train-loss: 0.502 | valid-loss: 38.775 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 390\n",
      "\t train-loss: 0.475 | valid-loss: 37.215 \t| valid-metric: 0.321 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 391\n",
      "\t train-loss: 0.484 | valid-loss: 37.367 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 392\n",
      "\t train-loss: 0.519 | valid-loss: 37.257 \t| valid-metric: 0.321 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 393\n",
      "\t train-loss: 0.561 | valid-loss: 38.439 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 394\n",
      "\t train-loss: 0.526 | valid-loss: 38.347 \t| valid-metric: 0.326 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 395\n",
      "\t train-loss: 0.498 | valid-loss: 37.283 \t| valid-metric: 0.321 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 396\n",
      "\t train-loss: 0.475 | valid-loss: 37.659 \t| valid-metric: 0.323 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 397\n",
      "\t train-loss: 0.47 | valid-loss: 36.67 \t| valid-metric: 0.319 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.319. Saving model...\n",
      "\n",
      "Iter 0\n",
      " Epoch 398\n",
      "\t train-loss: 0.479 | valid-loss: 37.317 \t| valid-metric: 0.322 | lr: 0.01\n",
      "Iter 0\n",
      " Epoch 399\n",
      "\t train-loss: 0.465 | valid-loss: 36.5 \t| valid-metric: 0.318 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.318. Saving model...\n",
      "\n",
      "Training is finished.\n",
      "Best model was at epoch: 399\n",
      "[[0.3464, 0.3576, 0.3807, 0.4105, 0.4429]]\n",
      "**************************************************************************************************** iter: 1****************************************************************************************************\n",
      "CITRUS(\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "  (encoder): Linear(in_features=5, out_features=4, bias=True)\n",
      "  (CPGNN): CPGNN_ST_in_TTS(\n",
      "    (last_activation): LeakyReLU(negative_slope=0.01)\n",
      "    (first_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (last_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (merge_lin): Linear(in_features=1090, out_features=1, bias=True)\n",
      "    (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "    (block_0): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_1): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_2): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=1)\n",
      ")\n",
      "Number of parameters: 2544.0\n",
      "11 batches per epoch (3051 trn samples in total | batch_size: 256)\n",
      "Iter 1\n",
      " Epoch 0\n",
      "\t train-loss: 150.777 | valid-loss: 192.213 \t| valid-metric: 0.73 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.73. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 1\n",
      "\t train-loss: 71.558 | valid-loss: 82.239 \t| valid-metric: 0.477 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.477. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 2\n",
      "\t train-loss: 48.704 | valid-loss: 86.067 \t| valid-metric: 0.488 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 3\n",
      "\t train-loss: 40.574 | valid-loss: 60.249 \t| valid-metric: 0.409 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.409. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 4\n",
      "\t train-loss: 35.427 | valid-loss: 61.856 \t| valid-metric: 0.414 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 5\n",
      "\t train-loss: 30.818 | valid-loss: 51.829 \t| valid-metric: 0.379 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.379. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 6\n",
      "\t train-loss: 26.668 | valid-loss: 46.84 \t| valid-metric: 0.36 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.36. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 7\n",
      "\t train-loss: 22.463 | valid-loss: 35.14 \t| valid-metric: 0.312 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.312. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 8\n",
      "\t train-loss: 18.412 | valid-loss: 27.371 \t| valid-metric: 0.275 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.275. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 9\n",
      "\t train-loss: 14.396 | valid-loss: 21.164 \t| valid-metric: 0.242 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.242. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 10\n",
      "\t train-loss: 11.03 | valid-loss: 15.981 \t| valid-metric: 0.21 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.21. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 11\n",
      "\t train-loss: 8.964 | valid-loss: 20.656 \t| valid-metric: 0.239 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 12\n",
      "\t train-loss: 8.006 | valid-loss: 18.021 \t| valid-metric: 0.223 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 13\n",
      "\t train-loss: 7.327 | valid-loss: 13.661 \t| valid-metric: 0.195 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.195. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 14\n",
      "\t train-loss: 6.629 | valid-loss: 10.668 \t| valid-metric: 0.172 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.172. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 15\n",
      "\t train-loss: 5.95 | valid-loss: 10.907 \t| valid-metric: 0.174 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 16\n",
      "\t train-loss: 5.306 | valid-loss: 7.819 \t| valid-metric: 0.147 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.147. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 17\n",
      "\t train-loss: 4.767 | valid-loss: 7.145 \t| valid-metric: 0.141 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.141. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 18\n",
      "\t train-loss: 4.313 | valid-loss: 6.655 \t| valid-metric: 0.136 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.136. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 19\n",
      "\t train-loss: 3.948 | valid-loss: 5.788 \t| valid-metric: 0.127 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.127. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 20\n",
      "\t train-loss: 3.694 | valid-loss: 4.926 \t| valid-metric: 0.117 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.117. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 21\n",
      "\t train-loss: 3.462 | valid-loss: 4.745 \t| valid-metric: 0.115 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.115. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 22\n",
      "\t train-loss: 3.302 | valid-loss: 4.201 \t| valid-metric: 0.108 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.108. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 23\n",
      "\t train-loss: 3.192 | valid-loss: 5.298 \t| valid-metric: 0.121 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 24\n",
      "\t train-loss: 3.096 | valid-loss: 3.461 \t| valid-metric: 0.098 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.098. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 25\n",
      "\t train-loss: 2.994 | valid-loss: 3.293 \t| valid-metric: 0.096 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.096. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 26\n",
      "\t train-loss: 2.911 | valid-loss: 3.385 \t| valid-metric: 0.097 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 27\n",
      "\t train-loss: 2.837 | valid-loss: 4.667 \t| valid-metric: 0.114 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 28\n",
      "\t train-loss: 2.769 | valid-loss: 3.009 \t| valid-metric: 0.091 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.091. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 29\n",
      "\t train-loss: 2.686 | valid-loss: 2.92 \t| valid-metric: 0.09 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.09. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 30\n",
      "\t train-loss: 2.609 | valid-loss: 2.988 \t| valid-metric: 0.091 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 31\n",
      "\t train-loss: 2.544 | valid-loss: 2.715 \t| valid-metric: 0.087 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.087. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 32\n",
      "\t train-loss: 2.517 | valid-loss: 2.997 \t| valid-metric: 0.091 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 33\n",
      "\t train-loss: 2.436 | valid-loss: 2.745 \t| valid-metric: 0.087 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 34\n",
      "\t train-loss: 2.355 | valid-loss: 2.512 \t| valid-metric: 0.083 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.083. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 35\n",
      "\t train-loss: 2.283 | valid-loss: 2.57 \t| valid-metric: 0.084 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 36\n",
      "\t train-loss: 2.231 | valid-loss: 2.341 \t| valid-metric: 0.081 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.081. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 37\n",
      "\t train-loss: 2.172 | valid-loss: 2.286 \t| valid-metric: 0.08 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.08. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 38\n",
      "\t train-loss: 2.122 | valid-loss: 2.227 \t| valid-metric: 0.079 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.079. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 39\n",
      "\t train-loss: 2.097 | valid-loss: 2.37 \t| valid-metric: 0.081 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 40\n",
      "\t train-loss: 2.039 | valid-loss: 2.114 \t| valid-metric: 0.077 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.077. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 41\n",
      "\t train-loss: 1.945 | valid-loss: 2.245 \t| valid-metric: 0.079 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 42\n",
      "\t train-loss: 1.888 | valid-loss: 2.525 \t| valid-metric: 0.084 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 43\n",
      "\t train-loss: 1.85 | valid-loss: 2.181 \t| valid-metric: 0.078 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 44\n",
      "\t train-loss: 1.794 | valid-loss: 1.883 \t| valid-metric: 0.072 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.072. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 45\n",
      "\t train-loss: 1.743 | valid-loss: 1.886 \t| valid-metric: 0.072 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 46\n",
      "\t train-loss: 1.687 | valid-loss: 2.361 \t| valid-metric: 0.081 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 47\n",
      "\t train-loss: 1.638 | valid-loss: 1.993 \t| valid-metric: 0.074 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 48\n",
      "\t train-loss: 1.625 | valid-loss: 2.169 \t| valid-metric: 0.078 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 49\n",
      "\t train-loss: 1.556 | valid-loss: 2.432 \t| valid-metric: 0.082 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 50\n",
      "\t train-loss: 1.507 | valid-loss: 1.807 \t| valid-metric: 0.071 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.071. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 51\n",
      "\t train-loss: 1.443 | valid-loss: 1.986 \t| valid-metric: 0.074 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 52\n",
      "\t train-loss: 1.405 | valid-loss: 2.012 \t| valid-metric: 0.075 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 53\n",
      "\t train-loss: 1.36 | valid-loss: 1.528 \t| valid-metric: 0.065 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.065. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 54\n",
      "\t train-loss: 1.315 | valid-loss: 1.415 \t| valid-metric: 0.063 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.063. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 55\n",
      "\t train-loss: 1.308 | valid-loss: 1.335 \t| valid-metric: 0.061 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.061. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 56\n",
      "\t train-loss: 1.246 | valid-loss: 1.604 \t| valid-metric: 0.067 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 57\n",
      "\t train-loss: 1.216 | valid-loss: 1.274 \t| valid-metric: 0.059 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.059. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 58\n",
      "\t train-loss: 1.172 | valid-loss: 1.462 \t| valid-metric: 0.064 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 59\n",
      "\t train-loss: 1.13 | valid-loss: 1.272 \t| valid-metric: 0.059 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 60\n",
      "\t train-loss: 1.08 | valid-loss: 1.458 \t| valid-metric: 0.064 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 61\n",
      "\t train-loss: 1.049 | valid-loss: 1.438 \t| valid-metric: 0.063 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 62\n",
      "\t train-loss: 1.036 | valid-loss: 1.022 \t| valid-metric: 0.053 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.053. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 63\n",
      "\t train-loss: 0.985 | valid-loss: 1.103 \t| valid-metric: 0.055 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 64\n",
      "\t train-loss: 0.946 | valid-loss: 0.951 \t| valid-metric: 0.051 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.051. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 65\n",
      "\t train-loss: 0.92 | valid-loss: 0.922 \t| valid-metric: 0.051 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 66\n",
      "\t train-loss: 0.908 | valid-loss: 1.018 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 67\n",
      "\t train-loss: 0.865 | valid-loss: 0.945 \t| valid-metric: 0.051 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 68\n",
      "\t train-loss: 0.825 | valid-loss: 1.003 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 69\n",
      "\t train-loss: 0.8 | valid-loss: 0.817 \t| valid-metric: 0.048 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.048. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 70\n",
      "\t train-loss: 0.779 | valid-loss: 0.796 \t| valid-metric: 0.047 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.047. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 71\n",
      "\t train-loss: 0.754 | valid-loss: 0.859 \t| valid-metric: 0.049 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 72\n",
      "\t train-loss: 0.741 | valid-loss: 0.757 \t| valid-metric: 0.046 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.046. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 73\n",
      "\t train-loss: 0.73 | valid-loss: 0.764 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 74\n",
      "\t train-loss: 0.698 | valid-loss: 0.725 \t| valid-metric: 0.045 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.045. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 75\n",
      "\t train-loss: 0.68 | valid-loss: 0.684 \t| valid-metric: 0.044 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.044. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 76\n",
      "\t train-loss: 0.672 | valid-loss: 0.797 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 77\n",
      "\t train-loss: 0.672 | valid-loss: 0.821 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 78\n",
      "\t train-loss: 0.639 | valid-loss: 0.67 \t| valid-metric: 0.043 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.043. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 79\n",
      "\t train-loss: 0.628 | valid-loss: 0.841 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 80\n",
      "\t train-loss: 0.631 | valid-loss: 0.673 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 81\n",
      "\t train-loss: 0.638 | valid-loss: 0.607 \t| valid-metric: 0.041 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.041. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 82\n",
      "\t train-loss: 0.602 | valid-loss: 0.617 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 83\n",
      "\t train-loss: 0.61 | valid-loss: 0.6 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 84\n",
      "\t train-loss: 0.588 | valid-loss: 0.588 \t| valid-metric: 0.04 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.04. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 85\n",
      "\t train-loss: 0.578 | valid-loss: 0.612 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 86\n",
      "\t train-loss: 0.577 | valid-loss: 0.607 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 87\n",
      "\t train-loss: 0.6 | valid-loss: 0.588 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 88\n",
      "\t train-loss: 0.574 | valid-loss: 0.612 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 89\n",
      "\t train-loss: 0.559 | valid-loss: 0.681 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 90\n",
      "\t train-loss: 0.564 | valid-loss: 0.617 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 91\n",
      "\t train-loss: 0.56 | valid-loss: 0.565 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 92\n",
      "\t train-loss: 0.566 | valid-loss: 0.574 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 93\n",
      "\t train-loss: 0.562 | valid-loss: 0.579 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 94\n",
      "\t train-loss: 0.551 | valid-loss: 0.569 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 95\n",
      "\t train-loss: 0.552 | valid-loss: 0.559 \t| valid-metric: 0.039 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.039. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 96\n",
      "\t train-loss: 0.543 | valid-loss: 0.552 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 97\n",
      "\t train-loss: 0.547 | valid-loss: 0.597 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 98\n",
      "\t train-loss: 0.545 | valid-loss: 0.554 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 99\n",
      "\t train-loss: 0.544 | valid-loss: 0.541 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 100\n",
      "\t train-loss: 0.534 | valid-loss: 0.583 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 101\n",
      "\t train-loss: 0.533 | valid-loss: 0.586 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 102\n",
      "\t train-loss: 0.524 | valid-loss: 0.562 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 103\n",
      "\t train-loss: 0.527 | valid-loss: 0.534 \t| valid-metric: 0.038 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.038. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 104\n",
      "\t train-loss: 0.528 | valid-loss: 0.55 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 105\n",
      "\t train-loss: 0.544 | valid-loss: 0.612 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 106\n",
      "\t train-loss: 0.556 | valid-loss: 0.533 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 107\n",
      "\t train-loss: 0.542 | valid-loss: 0.739 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 108\n",
      "\t train-loss: 0.561 | valid-loss: 0.55 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 109\n",
      "\t train-loss: 0.539 | valid-loss: 0.776 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 110\n",
      "\t train-loss: 0.531 | valid-loss: 0.533 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 111\n",
      "\t train-loss: 0.528 | valid-loss: 0.526 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 112\n",
      "\t train-loss: 0.518 | valid-loss: 0.537 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 113\n",
      "\t train-loss: 0.513 | valid-loss: 0.534 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 114\n",
      "\t train-loss: 0.516 | valid-loss: 0.528 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 115\n",
      "\t train-loss: 0.515 | valid-loss: 0.609 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 116\n",
      "\t train-loss: 0.503 | valid-loss: 0.671 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 117\n",
      "\t train-loss: 0.498 | valid-loss: 0.533 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 118\n",
      "\t train-loss: 0.495 | valid-loss: 0.517 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 119\n",
      "\t train-loss: 0.498 | valid-loss: 0.503 \t| valid-metric: 0.037 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.037. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 120\n",
      "\t train-loss: 0.509 | valid-loss: 0.54 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 121\n",
      "\t train-loss: 0.497 | valid-loss: 0.498 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 122\n",
      "\t train-loss: 0.49 | valid-loss: 0.504 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 123\n",
      "\t train-loss: 0.487 | valid-loss: 0.568 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 124\n",
      "\t train-loss: 0.513 | valid-loss: 0.62 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 125\n",
      "\t train-loss: 0.505 | valid-loss: 0.523 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 126\n",
      "\t train-loss: 0.521 | valid-loss: 0.501 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 127\n",
      "\t train-loss: 0.502 | valid-loss: 0.494 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 128\n",
      "\t train-loss: 0.495 | valid-loss: 0.493 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 129\n",
      "\t train-loss: 0.478 | valid-loss: 0.487 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 130\n",
      "\t train-loss: 0.495 | valid-loss: 0.642 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 131\n",
      "\t train-loss: 0.508 | valid-loss: 0.607 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 132\n",
      "\t train-loss: 0.495 | valid-loss: 0.504 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 133\n",
      "\t train-loss: 0.473 | valid-loss: 0.486 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 134\n",
      "\t train-loss: 0.478 | valid-loss: 0.481 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 135\n",
      "\t train-loss: 0.47 | valid-loss: 0.498 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 136\n",
      "\t train-loss: 0.475 | valid-loss: 0.509 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 137\n",
      "\t train-loss: 0.488 | valid-loss: 0.483 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 138\n",
      "\t train-loss: 0.494 | valid-loss: 0.782 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 139\n",
      "\t train-loss: 0.494 | valid-loss: 0.491 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 140\n",
      "\t train-loss: 0.501 | valid-loss: 0.534 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 141\n",
      "\t train-loss: 0.497 | valid-loss: 0.521 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 142\n",
      "\t train-loss: 0.487 | valid-loss: 0.478 \t| valid-metric: 0.036 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.036. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 143\n",
      "\t train-loss: 0.47 | valid-loss: 0.472 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 144\n",
      "\t train-loss: 0.464 | valid-loss: 0.495 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 145\n",
      "\t train-loss: 0.458 | valid-loss: 0.505 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 146\n",
      "\t train-loss: 0.461 | valid-loss: 0.474 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 147\n",
      "\t train-loss: 0.46 | valid-loss: 0.472 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 148\n",
      "\t train-loss: 0.457 | valid-loss: 0.527 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 149\n",
      "\t train-loss: 0.46 | valid-loss: 0.488 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 150\n",
      "\t train-loss: 0.471 | valid-loss: 0.484 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 151\n",
      "\t train-loss: 0.461 | valid-loss: 0.455 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 152\n",
      "\t train-loss: 0.457 | valid-loss: 0.504 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 153\n",
      "\t train-loss: 0.463 | valid-loss: 0.508 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 154\n",
      "\t train-loss: 0.486 | valid-loss: 0.452 \t| valid-metric: 0.035 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.035. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 155\n",
      "\t train-loss: 0.459 | valid-loss: 0.454 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 156\n",
      "\t train-loss: 0.452 | valid-loss: 0.455 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 157\n",
      "\t train-loss: 0.451 | valid-loss: 0.46 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 158\n",
      "\t train-loss: 0.448 | valid-loss: 0.465 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 159\n",
      "\t train-loss: 0.452 | valid-loss: 0.643 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 160\n",
      "\t train-loss: 0.446 | valid-loss: 0.456 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 161\n",
      "\t train-loss: 0.481 | valid-loss: 0.453 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 162\n",
      "\t train-loss: 0.441 | valid-loss: 0.463 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 163\n",
      "\t train-loss: 0.448 | valid-loss: 0.445 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 164\n",
      "\t train-loss: 0.464 | valid-loss: 0.508 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 165\n",
      "\t train-loss: 0.451 | valid-loss: 0.451 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 166\n",
      "\t train-loss: 0.44 | valid-loss: 0.573 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 167\n",
      "\t train-loss: 0.44 | valid-loss: 0.442 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 168\n",
      "\t train-loss: 0.438 | valid-loss: 0.494 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 169\n",
      "\t train-loss: 0.448 | valid-loss: 0.45 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 170\n",
      "\t train-loss: 0.436 | valid-loss: 0.498 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 171\n",
      "\t train-loss: 0.443 | valid-loss: 0.445 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 172\n",
      "\t train-loss: 0.43 | valid-loss: 0.496 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 173\n",
      "\t train-loss: 0.432 | valid-loss: 0.444 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 174\n",
      "\t train-loss: 0.43 | valid-loss: 0.438 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 175\n",
      "\t train-loss: 0.429 | valid-loss: 0.454 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 176\n",
      "\t train-loss: 0.434 | valid-loss: 0.46 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 177\n",
      "\t train-loss: 0.443 | valid-loss: 0.442 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 178\n",
      "\t train-loss: 0.425 | valid-loss: 0.457 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 179\n",
      "\t train-loss: 0.429 | valid-loss: 0.441 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 180\n",
      "\t train-loss: 0.425 | valid-loss: 0.428 \t| valid-metric: 0.034 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.034. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 181\n",
      "\t train-loss: 0.431 | valid-loss: 0.467 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 182\n",
      "\t train-loss: 0.428 | valid-loss: 0.454 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 183\n",
      "\t train-loss: 0.426 | valid-loss: 0.432 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 184\n",
      "\t train-loss: 0.423 | valid-loss: 0.504 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 185\n",
      "\t train-loss: 0.462 | valid-loss: 0.499 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 186\n",
      "\t train-loss: 0.443 | valid-loss: 0.43 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 187\n",
      "\t train-loss: 0.432 | valid-loss: 0.499 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 188\n",
      "\t train-loss: 0.437 | valid-loss: 0.421 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 189\n",
      "\t train-loss: 0.422 | valid-loss: 0.52 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 190\n",
      "\t train-loss: 0.418 | valid-loss: 0.449 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 191\n",
      "\t train-loss: 0.416 | valid-loss: 0.431 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 192\n",
      "\t train-loss: 0.438 | valid-loss: 0.484 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 193\n",
      "\t train-loss: 0.456 | valid-loss: 0.459 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 194\n",
      "\t train-loss: 0.42 | valid-loss: 0.432 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 195\n",
      "\t train-loss: 0.413 | valid-loss: 0.426 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 196\n",
      "\t train-loss: 0.426 | valid-loss: 0.543 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 197\n",
      "\t train-loss: 0.466 | valid-loss: 0.476 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 198\n",
      "\t train-loss: 0.418 | valid-loss: 0.566 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 199\n",
      "\t train-loss: 0.435 | valid-loss: 0.415 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 200\n",
      "\t train-loss: 0.411 | valid-loss: 0.42 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 201\n",
      "\t train-loss: 0.417 | valid-loss: 0.459 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 202\n",
      "\t train-loss: 0.422 | valid-loss: 0.484 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 203\n",
      "\t train-loss: 0.417 | valid-loss: 0.43 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 204\n",
      "\t train-loss: 0.409 | valid-loss: 0.426 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 205\n",
      "\t train-loss: 0.404 | valid-loss: 0.424 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 206\n",
      "\t train-loss: 0.401 | valid-loss: 0.408 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 207\n",
      "\t train-loss: 0.405 | valid-loss: 0.418 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 208\n",
      "\t train-loss: 0.405 | valid-loss: 0.409 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 209\n",
      "\t train-loss: 0.405 | valid-loss: 0.409 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 210\n",
      "\t train-loss: 0.399 | valid-loss: 0.418 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 211\n",
      "\t train-loss: 0.435 | valid-loss: 0.417 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 212\n",
      "\t train-loss: 0.41 | valid-loss: 0.415 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 213\n",
      "\t train-loss: 0.42 | valid-loss: 0.494 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 214\n",
      "\t train-loss: 0.404 | valid-loss: 0.438 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 215\n",
      "\t train-loss: 0.4 | valid-loss: 0.4 \t| valid-metric: 0.033 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.033. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 216\n",
      "\t train-loss: 0.447 | valid-loss: 0.459 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 217\n",
      "\t train-loss: 0.432 | valid-loss: 0.476 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 218\n",
      "\t train-loss: 0.401 | valid-loss: 0.426 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 219\n",
      "\t train-loss: 0.397 | valid-loss: 0.467 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 220\n",
      "\t train-loss: 0.41 | valid-loss: 0.53 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 221\n",
      "\t train-loss: 0.41 | valid-loss: 0.41 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 222\n",
      "\t train-loss: 0.415 | valid-loss: 0.412 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 223\n",
      "\t train-loss: 0.405 | valid-loss: 0.45 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 224\n",
      "\t train-loss: 0.396 | valid-loss: 0.401 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 225\n",
      "\t train-loss: 0.401 | valid-loss: 0.425 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 226\n",
      "\t train-loss: 0.42 | valid-loss: 0.558 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 227\n",
      "\t train-loss: 0.4 | valid-loss: 0.46 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 228\n",
      "\t train-loss: 0.393 | valid-loss: 0.453 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 229\n",
      "\t train-loss: 0.393 | valid-loss: 0.409 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 230\n",
      "\t train-loss: 0.391 | valid-loss: 0.432 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 231\n",
      "\t train-loss: 0.393 | valid-loss: 0.396 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 232\n",
      "\t train-loss: 0.4 | valid-loss: 0.613 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 233\n",
      "\t train-loss: 0.419 | valid-loss: 0.392 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 234\n",
      "\t train-loss: 0.4 | valid-loss: 0.438 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 235\n",
      "\t train-loss: 0.391 | valid-loss: 0.446 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 236\n",
      "\t train-loss: 0.411 | valid-loss: 0.452 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 237\n",
      "\t train-loss: 0.406 | valid-loss: 0.759 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 238\n",
      "\t train-loss: 0.391 | valid-loss: 0.399 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 239\n",
      "\t train-loss: 0.39 | valid-loss: 0.4 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 240\n",
      "\t train-loss: 0.388 | valid-loss: 0.392 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 241\n",
      "\t train-loss: 0.383 | valid-loss: 0.41 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 242\n",
      "\t train-loss: 0.387 | valid-loss: 0.437 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 243\n",
      "\t train-loss: 0.402 | valid-loss: 0.466 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 244\n",
      "\t train-loss: 0.406 | valid-loss: 0.385 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 245\n",
      "\t train-loss: 0.414 | valid-loss: 0.738 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 246\n",
      "\t train-loss: 0.414 | valid-loss: 0.545 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 247\n",
      "\t train-loss: 0.402 | valid-loss: 0.422 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 248\n",
      "\t train-loss: 0.426 | valid-loss: 0.425 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 249\n",
      "\t train-loss: 0.474 | valid-loss: 0.418 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 250\n",
      "\t train-loss: 0.414 | valid-loss: 0.532 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 251\n",
      "\t train-loss: 0.387 | valid-loss: 0.406 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 252\n",
      "\t train-loss: 0.384 | valid-loss: 0.384 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 253\n",
      "\t train-loss: 0.383 | valid-loss: 0.439 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 254\n",
      "\t train-loss: 0.407 | valid-loss: 0.54 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 255\n",
      "\t train-loss: 0.393 | valid-loss: 0.422 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 256\n",
      "\t train-loss: 0.395 | valid-loss: 0.393 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 257\n",
      "\t train-loss: 0.387 | valid-loss: 0.398 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 258\n",
      "\t train-loss: 0.395 | valid-loss: 0.465 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 259\n",
      "\t train-loss: 0.395 | valid-loss: 0.419 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 260\n",
      "\t train-loss: 0.398 | valid-loss: 0.385 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 261\n",
      "\t train-loss: 0.39 | valid-loss: 0.386 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 262\n",
      "\t train-loss: 0.395 | valid-loss: 0.513 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 263\n",
      "\t train-loss: 0.397 | valid-loss: 0.443 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 264\n",
      "\t train-loss: 0.433 | valid-loss: 0.479 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 265\n",
      "\t train-loss: 0.436 | valid-loss: 0.584 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 266\n",
      "\t train-loss: 0.41 | valid-loss: 0.563 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 267\n",
      "\t train-loss: 0.389 | valid-loss: 0.385 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 268\n",
      "\t train-loss: 0.381 | valid-loss: 0.381 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 269\n",
      "\t train-loss: 0.393 | valid-loss: 0.477 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 270\n",
      "\t train-loss: 0.4 | valid-loss: 0.417 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 271\n",
      "\t train-loss: 0.378 | valid-loss: 0.383 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 272\n",
      "\t train-loss: 0.384 | valid-loss: 0.409 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 273\n",
      "\t train-loss: 0.39 | valid-loss: 0.514 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 274\n",
      "\t train-loss: 0.376 | valid-loss: 0.377 \t| valid-metric: 0.032 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.032. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 275\n",
      "\t train-loss: 0.382 | valid-loss: 0.415 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 276\n",
      "\t train-loss: 0.384 | valid-loss: 0.401 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 277\n",
      "\t train-loss: 0.39 | valid-loss: 0.418 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 278\n",
      "\t train-loss: 0.408 | valid-loss: 0.421 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 279\n",
      "\t train-loss: 0.389 | valid-loss: 0.385 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 280\n",
      "\t train-loss: 0.398 | valid-loss: 0.39 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 281\n",
      "\t train-loss: 0.401 | valid-loss: 0.379 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 282\n",
      "\t train-loss: 0.394 | valid-loss: 0.468 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 283\n",
      "\t train-loss: 0.371 | valid-loss: 0.38 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 284\n",
      "\t train-loss: 0.371 | valid-loss: 0.391 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 285\n",
      "\t train-loss: 0.369 | valid-loss: 0.383 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 286\n",
      "\t train-loss: 0.394 | valid-loss: 0.385 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 287\n",
      "\t train-loss: 0.415 | valid-loss: 0.66 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 288\n",
      "\t train-loss: 0.406 | valid-loss: 0.394 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 289\n",
      "\t train-loss: 0.373 | valid-loss: 0.374 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 290\n",
      "\t train-loss: 0.37 | valid-loss: 0.399 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 291\n",
      "\t train-loss: 0.376 | valid-loss: 0.374 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 292\n",
      "\t train-loss: 0.375 | valid-loss: 0.392 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 293\n",
      "\t train-loss: 0.369 | valid-loss: 0.399 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 294\n",
      "\t train-loss: 0.371 | valid-loss: 0.401 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 295\n",
      "\t train-loss: 0.37 | valid-loss: 0.376 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 296\n",
      "\t train-loss: 0.392 | valid-loss: 0.439 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 297\n",
      "\t train-loss: 0.389 | valid-loss: 0.404 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 298\n",
      "\t train-loss: 0.39 | valid-loss: 0.528 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 299\n",
      "\t train-loss: 0.376 | valid-loss: 0.393 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 300\n",
      "\t train-loss: 0.371 | valid-loss: 0.374 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 301\n",
      "\t train-loss: 0.379 | valid-loss: 0.387 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 302\n",
      "\t train-loss: 0.393 | valid-loss: 0.382 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 303\n",
      "\t train-loss: 0.372 | valid-loss: 0.393 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 304\n",
      "\t train-loss: 0.369 | valid-loss: 0.374 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 305\n",
      "\t train-loss: 0.369 | valid-loss: 0.403 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 306\n",
      "\t train-loss: 0.394 | valid-loss: 0.453 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 307\n",
      "\t train-loss: 0.402 | valid-loss: 0.379 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 308\n",
      "\t train-loss: 0.422 | valid-loss: 0.369 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 309\n",
      "\t train-loss: 0.408 | valid-loss: 0.37 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 310\n",
      "\t train-loss: 0.365 | valid-loss: 0.407 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 311\n",
      "\t train-loss: 0.368 | valid-loss: 0.377 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 312\n",
      "\t train-loss: 0.366 | valid-loss: 0.585 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 313\n",
      "\t train-loss: 0.372 | valid-loss: 0.382 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 314\n",
      "\t train-loss: 0.369 | valid-loss: 0.371 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 315\n",
      "\t train-loss: 0.365 | valid-loss: 0.389 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 316\n",
      "\t train-loss: 0.373 | valid-loss: 0.369 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 317\n",
      "\t train-loss: 0.386 | valid-loss: 0.46 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 318\n",
      "\t train-loss: 0.369 | valid-loss: 0.377 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 319\n",
      "\t train-loss: 0.369 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 320\n",
      "\t train-loss: 0.371 | valid-loss: 0.374 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 321\n",
      "\t train-loss: 0.37 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 322\n",
      "\t train-loss: 0.365 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 323\n",
      "\t train-loss: 0.366 | valid-loss: 0.408 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 324\n",
      "\t train-loss: 0.367 | valid-loss: 0.424 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 325\n",
      "\t train-loss: 0.366 | valid-loss: 0.526 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 326\n",
      "\t train-loss: 0.417 | valid-loss: 0.496 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 327\n",
      "\t train-loss: 0.4 | valid-loss: 0.481 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 328\n",
      "\t train-loss: 0.362 | valid-loss: 0.383 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 329\n",
      "\t train-loss: 0.359 | valid-loss: 0.372 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 330\n",
      "\t train-loss: 0.364 | valid-loss: 0.366 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 331\n",
      "\t train-loss: 0.359 | valid-loss: 0.376 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 332\n",
      "\t train-loss: 0.367 | valid-loss: 0.38 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 333\n",
      "\t train-loss: 0.369 | valid-loss: 0.438 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 334\n",
      "\t train-loss: 0.368 | valid-loss: 0.393 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 335\n",
      "\t train-loss: 0.37 | valid-loss: 0.378 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 336\n",
      "\t train-loss: 0.369 | valid-loss: 0.38 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 337\n",
      "\t train-loss: 0.368 | valid-loss: 0.367 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 338\n",
      "\t train-loss: 0.361 | valid-loss: 0.419 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 339\n",
      "\t train-loss: 0.373 | valid-loss: 0.42 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 340\n",
      "\t train-loss: 0.363 | valid-loss: 0.371 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 341\n",
      "\t train-loss: 0.361 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 342\n",
      "\t train-loss: 0.366 | valid-loss: 0.403 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 343\n",
      "\t train-loss: 0.358 | valid-loss: 0.373 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 344\n",
      "\t train-loss: 0.373 | valid-loss: 0.366 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 345\n",
      "\t train-loss: 0.364 | valid-loss: 0.376 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 346\n",
      "\t train-loss: 0.357 | valid-loss: 0.368 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 347\n",
      "\t train-loss: 0.365 | valid-loss: 0.383 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 348\n",
      "\t train-loss: 0.363 | valid-loss: 0.381 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 349\n",
      "\t train-loss: 0.36 | valid-loss: 0.364 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 350\n",
      "\t train-loss: 0.369 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 351\n",
      "\t train-loss: 0.363 | valid-loss: 0.367 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 352\n",
      "\t train-loss: 0.369 | valid-loss: 0.363 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 353\n",
      "\t train-loss: 0.384 | valid-loss: 0.495 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 354\n",
      "\t train-loss: 0.38 | valid-loss: 0.455 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 355\n",
      "\t train-loss: 0.381 | valid-loss: 0.61 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 356\n",
      "\t train-loss: 0.379 | valid-loss: 0.373 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 357\n",
      "\t train-loss: 0.411 | valid-loss: 0.374 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 358\n",
      "\t train-loss: 0.407 | valid-loss: 0.368 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 359\n",
      "\t train-loss: 0.371 | valid-loss: 0.38 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 360\n",
      "\t train-loss: 0.374 | valid-loss: 0.544 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 361\n",
      "\t train-loss: 0.397 | valid-loss: 0.363 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 362\n",
      "\t train-loss: 0.408 | valid-loss: 0.422 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 363\n",
      "\t train-loss: 0.375 | valid-loss: 0.418 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 364\n",
      "\t train-loss: 0.354 | valid-loss: 0.442 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 365\n",
      "\t train-loss: 0.355 | valid-loss: 0.367 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 366\n",
      "\t train-loss: 0.362 | valid-loss: 0.408 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 367\n",
      "\t train-loss: 0.358 | valid-loss: 0.368 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 368\n",
      "\t train-loss: 0.357 | valid-loss: 0.36 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 369\n",
      "\t train-loss: 0.369 | valid-loss: 0.454 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 370\n",
      "\t train-loss: 0.388 | valid-loss: 0.371 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 371\n",
      "\t train-loss: 0.369 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 372\n",
      "\t train-loss: 0.359 | valid-loss: 0.448 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 373\n",
      "\t train-loss: 0.363 | valid-loss: 0.389 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 374\n",
      "\t train-loss: 0.357 | valid-loss: 0.376 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 375\n",
      "\t train-loss: 0.375 | valid-loss: 0.357 \t| valid-metric: 0.031 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.031. Saving model...\n",
      "\n",
      "Iter 1\n",
      " Epoch 376\n",
      "\t train-loss: 0.354 | valid-loss: 0.375 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 377\n",
      "\t train-loss: 0.367 | valid-loss: 0.37 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 378\n",
      "\t train-loss: 0.357 | valid-loss: 0.518 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 379\n",
      "\t train-loss: 0.368 | valid-loss: 0.364 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 380\n",
      "\t train-loss: 0.379 | valid-loss: 0.544 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 381\n",
      "\t train-loss: 0.358 | valid-loss: 0.405 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 382\n",
      "\t train-loss: 0.351 | valid-loss: 0.353 \t| valid-metric: 0.031 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 383\n",
      "\t train-loss: 0.358 | valid-loss: 0.379 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 384\n",
      "\t train-loss: 0.355 | valid-loss: 0.354 \t| valid-metric: 0.031 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 385\n",
      "\t train-loss: 0.363 | valid-loss: 0.533 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 386\n",
      "\t train-loss: 0.356 | valid-loss: 0.359 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 387\n",
      "\t train-loss: 0.353 | valid-loss: 0.53 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 388\n",
      "\t train-loss: 0.374 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 389\n",
      "\t train-loss: 0.373 | valid-loss: 0.395 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 390\n",
      "\t train-loss: 0.352 | valid-loss: 0.365 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 391\n",
      "\t train-loss: 0.349 | valid-loss: 0.358 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 392\n",
      "\t train-loss: 0.353 | valid-loss: 0.357 \t| valid-metric: 0.031 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 393\n",
      "\t train-loss: 0.348 | valid-loss: 0.364 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 394\n",
      "\t train-loss: 0.351 | valid-loss: 0.437 \t| valid-metric: 0.035 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 395\n",
      "\t train-loss: 0.355 | valid-loss: 0.349 \t| valid-metric: 0.031 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 396\n",
      "\t train-loss: 0.391 | valid-loss: 0.397 \t| valid-metric: 0.033 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 397\n",
      "\t train-loss: 0.369 | valid-loss: 0.489 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 398\n",
      "\t train-loss: 0.373 | valid-loss: 0.373 \t| valid-metric: 0.032 | lr: 0.01\n",
      "Iter 1\n",
      " Epoch 399\n",
      "\t train-loss: 0.395 | valid-loss: 0.41 \t| valid-metric: 0.034 | lr: 0.01\n",
      "Training is finished.\n",
      "Best model was at epoch: 375\n",
      "[[0.3464, 0.3576, 0.3807, 0.4105, 0.4429], [0.038, 0.1199, 0.2076, 0.289, 0.3627]]\n",
      "**************************************************************************************************** iter: 2****************************************************************************************************\n",
      "CITRUS(\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "  (encoder): Linear(in_features=5, out_features=4, bias=True)\n",
      "  (CPGNN): CPGNN_ST_in_TTS(\n",
      "    (last_activation): LeakyReLU(negative_slope=0.01)\n",
      "    (first_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (last_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (merge_lin): Linear(in_features=1090, out_features=1, bias=True)\n",
      "    (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "    (block_0): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_1): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_2): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=1)\n",
      ")\n",
      "Number of parameters: 2544.0\n",
      "11 batches per epoch (3051 trn samples in total | batch_size: 256)\n",
      "Iter 2\n",
      " Epoch 0\n",
      "\t train-loss: 166.958 | valid-loss: 358.359 \t| valid-metric: 0.997 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.997. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 1\n",
      "\t train-loss: 155.055 | valid-loss: 262.339 \t| valid-metric: 0.853 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.853. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 2\n",
      "\t train-loss: 64.604 | valid-loss: 43.29 \t| valid-metric: 0.346 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.346. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 3\n",
      "\t train-loss: 23.956 | valid-loss: 48.038 \t| valid-metric: 0.365 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 4\n",
      "\t train-loss: 16.745 | valid-loss: 27.026 \t| valid-metric: 0.274 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.274. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 5\n",
      "\t train-loss: 14.321 | valid-loss: 28.377 \t| valid-metric: 0.28 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 6\n",
      "\t train-loss: 13.145 | valid-loss: 31.834 \t| valid-metric: 0.297 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 7\n",
      "\t train-loss: 12.345 | valid-loss: 26.687 \t| valid-metric: 0.272 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.272. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 8\n",
      "\t train-loss: 11.664 | valid-loss: 27.211 \t| valid-metric: 0.275 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 9\n",
      "\t train-loss: 10.972 | valid-loss: 23.971 \t| valid-metric: 0.258 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.258. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 10\n",
      "\t train-loss: 10.266 | valid-loss: 20.223 \t| valid-metric: 0.237 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.237. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 11\n",
      "\t train-loss: 9.617 | valid-loss: 19.749 \t| valid-metric: 0.234 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.234. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 12\n",
      "\t train-loss: 8.953 | valid-loss: 18.284 \t| valid-metric: 0.225 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.225. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 13\n",
      "\t train-loss: 8.322 | valid-loss: 16.841 \t| valid-metric: 0.216 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.216. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 14\n",
      "\t train-loss: 7.734 | valid-loss: 15.061 \t| valid-metric: 0.204 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.204. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 15\n",
      "\t train-loss: 7.194 | valid-loss: 12.297 \t| valid-metric: 0.185 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.185. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 16\n",
      "\t train-loss: 6.683 | valid-loss: 11.036 \t| valid-metric: 0.175 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.175. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 17\n",
      "\t train-loss: 6.142 | valid-loss: 10.075 \t| valid-metric: 0.167 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.167. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 18\n",
      "\t train-loss: 5.685 | valid-loss: 10.443 \t| valid-metric: 0.17 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 19\n",
      "\t train-loss: 5.251 | valid-loss: 7.562 \t| valid-metric: 0.145 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.145. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 20\n",
      "\t train-loss: 4.89 | valid-loss: 7.558 \t| valid-metric: 0.145 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 21\n",
      "\t train-loss: 4.542 | valid-loss: 7.589 \t| valid-metric: 0.145 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 22\n",
      "\t train-loss: 4.268 | valid-loss: 6.556 \t| valid-metric: 0.135 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.135. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 23\n",
      "\t train-loss: 4.045 | valid-loss: 5.943 \t| valid-metric: 0.128 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.128. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 24\n",
      "\t train-loss: 3.846 | valid-loss: 4.886 \t| valid-metric: 0.116 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.116. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 25\n",
      "\t train-loss: 3.716 | valid-loss: 4.579 \t| valid-metric: 0.113 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.113. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 26\n",
      "\t train-loss: 3.567 | valid-loss: 4.313 \t| valid-metric: 0.109 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.109. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 27\n",
      "\t train-loss: 3.45 | valid-loss: 3.885 \t| valid-metric: 0.104 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.104. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 28\n",
      "\t train-loss: 3.399 | valid-loss: 4.183 \t| valid-metric: 0.108 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 29\n",
      "\t train-loss: 3.322 | valid-loss: 3.695 \t| valid-metric: 0.101 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.101. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 30\n",
      "\t train-loss: 3.22 | valid-loss: 3.621 \t| valid-metric: 0.1 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.1. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 31\n",
      "\t train-loss: 3.158 | valid-loss: 3.835 \t| valid-metric: 0.103 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 32\n",
      "\t train-loss: 3.065 | valid-loss: 3.769 \t| valid-metric: 0.102 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 33\n",
      "\t train-loss: 3.002 | valid-loss: 3.609 \t| valid-metric: 0.1 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 34\n",
      "\t train-loss: 2.937 | valid-loss: 3.789 \t| valid-metric: 0.102 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 35\n",
      "\t train-loss: 2.874 | valid-loss: 3.292 \t| valid-metric: 0.096 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.096. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 36\n",
      "\t train-loss: 2.81 | valid-loss: 3.685 \t| valid-metric: 0.101 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 37\n",
      "\t train-loss: 2.756 | valid-loss: 3.062 \t| valid-metric: 0.092 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.092. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 38\n",
      "\t train-loss: 2.709 | valid-loss: 3.168 \t| valid-metric: 0.094 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 39\n",
      "\t train-loss: 2.654 | valid-loss: 3.534 \t| valid-metric: 0.099 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 40\n",
      "\t train-loss: 2.608 | valid-loss: 2.942 \t| valid-metric: 0.09 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.09. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 41\n",
      "\t train-loss: 2.559 | valid-loss: 3.042 \t| valid-metric: 0.092 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 42\n",
      "\t train-loss: 2.497 | valid-loss: 3.459 \t| valid-metric: 0.098 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 43\n",
      "\t train-loss: 2.454 | valid-loss: 2.724 \t| valid-metric: 0.087 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.087. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 44\n",
      "\t train-loss: 2.403 | valid-loss: 3.138 \t| valid-metric: 0.093 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 45\n",
      "\t train-loss: 2.366 | valid-loss: 3.614 \t| valid-metric: 0.1 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 46\n",
      "\t train-loss: 2.353 | valid-loss: 2.767 \t| valid-metric: 0.088 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 47\n",
      "\t train-loss: 2.275 | valid-loss: 2.512 \t| valid-metric: 0.083 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.083. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 48\n",
      "\t train-loss: 2.208 | valid-loss: 2.742 \t| valid-metric: 0.087 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 49\n",
      "\t train-loss: 2.176 | valid-loss: 2.504 \t| valid-metric: 0.083 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 50\n",
      "\t train-loss: 2.122 | valid-loss: 2.334 \t| valid-metric: 0.08 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.08. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 51\n",
      "\t train-loss: 2.094 | valid-loss: 2.594 \t| valid-metric: 0.085 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 52\n",
      "\t train-loss: 2.041 | valid-loss: 2.809 \t| valid-metric: 0.088 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 53\n",
      "\t train-loss: 2.0 | valid-loss: 2.212 \t| valid-metric: 0.078 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.078. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 54\n",
      "\t train-loss: 1.958 | valid-loss: 2.273 \t| valid-metric: 0.079 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 55\n",
      "\t train-loss: 1.914 | valid-loss: 2.344 \t| valid-metric: 0.081 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 56\n",
      "\t train-loss: 1.886 | valid-loss: 2.792 \t| valid-metric: 0.088 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 57\n",
      "\t train-loss: 1.835 | valid-loss: 2.289 \t| valid-metric: 0.08 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 58\n",
      "\t train-loss: 1.795 | valid-loss: 2.063 \t| valid-metric: 0.076 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.076. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 59\n",
      "\t train-loss: 1.754 | valid-loss: 2.118 \t| valid-metric: 0.077 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 60\n",
      "\t train-loss: 1.717 | valid-loss: 2.823 \t| valid-metric: 0.088 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 61\n",
      "\t train-loss: 1.697 | valid-loss: 1.91 \t| valid-metric: 0.073 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.073. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 62\n",
      "\t train-loss: 1.646 | valid-loss: 1.848 \t| valid-metric: 0.072 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.072. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 63\n",
      "\t train-loss: 1.614 | valid-loss: 1.934 \t| valid-metric: 0.073 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 64\n",
      "\t train-loss: 1.583 | valid-loss: 1.757 \t| valid-metric: 0.07 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.07. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 65\n",
      "\t train-loss: 1.539 | valid-loss: 1.87 \t| valid-metric: 0.072 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 66\n",
      "\t train-loss: 1.508 | valid-loss: 2.062 \t| valid-metric: 0.076 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 67\n",
      "\t train-loss: 1.471 | valid-loss: 1.715 \t| valid-metric: 0.069 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.069. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 68\n",
      "\t train-loss: 1.444 | valid-loss: 1.829 \t| valid-metric: 0.071 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 69\n",
      "\t train-loss: 1.408 | valid-loss: 1.872 \t| valid-metric: 0.072 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 70\n",
      "\t train-loss: 1.383 | valid-loss: 1.659 \t| valid-metric: 0.068 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.068. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 71\n",
      "\t train-loss: 1.349 | valid-loss: 1.739 \t| valid-metric: 0.069 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 72\n",
      "\t train-loss: 1.326 | valid-loss: 1.462 \t| valid-metric: 0.064 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.064. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 73\n",
      "\t train-loss: 1.307 | valid-loss: 1.537 \t| valid-metric: 0.065 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 74\n",
      "\t train-loss: 1.257 | valid-loss: 1.535 \t| valid-metric: 0.065 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 75\n",
      "\t train-loss: 1.224 | valid-loss: 1.477 \t| valid-metric: 0.064 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 76\n",
      "\t train-loss: 1.196 | valid-loss: 1.386 \t| valid-metric: 0.062 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.062. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 77\n",
      "\t train-loss: 1.171 | valid-loss: 1.355 \t| valid-metric: 0.061 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.061. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 78\n",
      "\t train-loss: 1.15 | valid-loss: 1.361 \t| valid-metric: 0.061 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 79\n",
      "\t train-loss: 1.112 | valid-loss: 1.268 \t| valid-metric: 0.059 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.059. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 80\n",
      "\t train-loss: 1.09 | valid-loss: 1.321 \t| valid-metric: 0.061 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 81\n",
      "\t train-loss: 1.064 | valid-loss: 1.387 \t| valid-metric: 0.062 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 82\n",
      "\t train-loss: 1.05 | valid-loss: 1.381 \t| valid-metric: 0.062 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 83\n",
      "\t train-loss: 1.022 | valid-loss: 1.14 \t| valid-metric: 0.056 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.056. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 84\n",
      "\t train-loss: 1.008 | valid-loss: 1.145 \t| valid-metric: 0.056 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 85\n",
      "\t train-loss: 0.981 | valid-loss: 1.219 \t| valid-metric: 0.058 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 86\n",
      "\t train-loss: 0.947 | valid-loss: 1.163 \t| valid-metric: 0.057 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 87\n",
      "\t train-loss: 0.93 | valid-loss: 1.351 \t| valid-metric: 0.061 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 88\n",
      "\t train-loss: 0.928 | valid-loss: 1.182 \t| valid-metric: 0.057 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 89\n",
      "\t train-loss: 0.906 | valid-loss: 1.027 \t| valid-metric: 0.053 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.053. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 90\n",
      "\t train-loss: 0.88 | valid-loss: 1.12 \t| valid-metric: 0.056 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 91\n",
      "\t train-loss: 0.859 | valid-loss: 1.024 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 92\n",
      "\t train-loss: 0.84 | valid-loss: 1.006 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 93\n",
      "\t train-loss: 0.823 | valid-loss: 1.088 \t| valid-metric: 0.055 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 94\n",
      "\t train-loss: 0.803 | valid-loss: 0.923 \t| valid-metric: 0.051 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.051. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 95\n",
      "\t train-loss: 0.796 | valid-loss: 1.03 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 96\n",
      "\t train-loss: 0.804 | valid-loss: 0.944 \t| valid-metric: 0.051 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 97\n",
      "\t train-loss: 0.778 | valid-loss: 1.249 \t| valid-metric: 0.059 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 98\n",
      "\t train-loss: 0.771 | valid-loss: 0.879 \t| valid-metric: 0.049 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.049. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 99\n",
      "\t train-loss: 0.755 | valid-loss: 0.949 \t| valid-metric: 0.051 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 100\n",
      "\t train-loss: 0.735 | valid-loss: 0.922 \t| valid-metric: 0.051 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 101\n",
      "\t train-loss: 0.731 | valid-loss: 0.925 \t| valid-metric: 0.051 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 102\n",
      "\t train-loss: 0.745 | valid-loss: 1.226 \t| valid-metric: 0.058 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 103\n",
      "\t train-loss: 0.726 | valid-loss: 0.853 \t| valid-metric: 0.049 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 104\n",
      "\t train-loss: 0.705 | valid-loss: 0.824 \t| valid-metric: 0.048 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.048. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 105\n",
      "\t train-loss: 0.691 | valid-loss: 0.819 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 106\n",
      "\t train-loss: 0.69 | valid-loss: 0.968 \t| valid-metric: 0.052 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 107\n",
      "\t train-loss: 0.694 | valid-loss: 0.895 \t| valid-metric: 0.05 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 108\n",
      "\t train-loss: 0.685 | valid-loss: 0.794 \t| valid-metric: 0.047 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.047. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 109\n",
      "\t train-loss: 0.682 | valid-loss: 0.821 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 110\n",
      "\t train-loss: 0.669 | valid-loss: 0.827 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 111\n",
      "\t train-loss: 0.656 | valid-loss: 0.795 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 112\n",
      "\t train-loss: 0.648 | valid-loss: 0.789 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 113\n",
      "\t train-loss: 0.645 | valid-loss: 0.78 \t| valid-metric: 0.046 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.046. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 114\n",
      "\t train-loss: 0.645 | valid-loss: 0.846 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 115\n",
      "\t train-loss: 0.643 | valid-loss: 0.779 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 116\n",
      "\t train-loss: 0.635 | valid-loss: 0.779 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 117\n",
      "\t train-loss: 0.631 | valid-loss: 0.756 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 118\n",
      "\t train-loss: 0.647 | valid-loss: 0.909 \t| valid-metric: 0.05 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 119\n",
      "\t train-loss: 0.653 | valid-loss: 0.768 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 120\n",
      "\t train-loss: 0.645 | valid-loss: 0.841 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 121\n",
      "\t train-loss: 0.62 | valid-loss: 0.739 \t| valid-metric: 0.045 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.045. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 122\n",
      "\t train-loss: 0.622 | valid-loss: 0.795 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 123\n",
      "\t train-loss: 0.612 | valid-loss: 0.784 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 124\n",
      "\t train-loss: 0.612 | valid-loss: 0.732 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 125\n",
      "\t train-loss: 0.607 | valid-loss: 0.713 \t| valid-metric: 0.044 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.044. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 126\n",
      "\t train-loss: 0.608 | valid-loss: 0.719 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 127\n",
      "\t train-loss: 0.61 | valid-loss: 0.709 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 128\n",
      "\t train-loss: 0.61 | valid-loss: 0.733 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 129\n",
      "\t train-loss: 0.603 | valid-loss: 0.711 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 130\n",
      "\t train-loss: 0.598 | valid-loss: 0.814 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 131\n",
      "\t train-loss: 0.6 | valid-loss: 0.795 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 132\n",
      "\t train-loss: 0.599 | valid-loss: 0.699 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 133\n",
      "\t train-loss: 0.591 | valid-loss: 0.689 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 134\n",
      "\t train-loss: 0.593 | valid-loss: 0.725 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 135\n",
      "\t train-loss: 0.59 | valid-loss: 0.735 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 136\n",
      "\t train-loss: 0.592 | valid-loss: 0.694 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 137\n",
      "\t train-loss: 0.598 | valid-loss: 0.688 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 138\n",
      "\t train-loss: 0.586 | valid-loss: 0.701 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 139\n",
      "\t train-loss: 0.581 | valid-loss: 0.706 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 140\n",
      "\t train-loss: 0.596 | valid-loss: 0.683 \t| valid-metric: 0.043 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.043. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 141\n",
      "\t train-loss: 0.59 | valid-loss: 0.68 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 142\n",
      "\t train-loss: 0.588 | valid-loss: 0.682 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 143\n",
      "\t train-loss: 0.578 | valid-loss: 0.676 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 144\n",
      "\t train-loss: 0.595 | valid-loss: 0.894 \t| valid-metric: 0.05 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 145\n",
      "\t train-loss: 0.589 | valid-loss: 0.762 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 146\n",
      "\t train-loss: 0.578 | valid-loss: 0.701 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 147\n",
      "\t train-loss: 0.569 | valid-loss: 0.669 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 148\n",
      "\t train-loss: 0.567 | valid-loss: 0.655 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 149\n",
      "\t train-loss: 0.568 | valid-loss: 0.651 \t| valid-metric: 0.042 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.042. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 150\n",
      "\t train-loss: 0.57 | valid-loss: 0.657 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 151\n",
      "\t train-loss: 0.576 | valid-loss: 0.652 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 152\n",
      "\t train-loss: 0.572 | valid-loss: 0.653 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 153\n",
      "\t train-loss: 0.563 | valid-loss: 0.838 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 154\n",
      "\t train-loss: 0.566 | valid-loss: 0.723 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 155\n",
      "\t train-loss: 0.567 | valid-loss: 0.657 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 156\n",
      "\t train-loss: 0.566 | valid-loss: 0.646 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 157\n",
      "\t train-loss: 0.565 | valid-loss: 0.663 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 158\n",
      "\t train-loss: 0.571 | valid-loss: 0.823 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 159\n",
      "\t train-loss: 0.573 | valid-loss: 0.781 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 160\n",
      "\t train-loss: 0.569 | valid-loss: 0.64 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 161\n",
      "\t train-loss: 0.564 | valid-loss: 0.636 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 162\n",
      "\t train-loss: 0.574 | valid-loss: 0.637 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 163\n",
      "\t train-loss: 0.564 | valid-loss: 0.636 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 164\n",
      "\t train-loss: 0.561 | valid-loss: 0.723 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 165\n",
      "\t train-loss: 0.553 | valid-loss: 0.691 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 166\n",
      "\t train-loss: 0.557 | valid-loss: 0.644 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 167\n",
      "\t train-loss: 0.563 | valid-loss: 0.67 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 168\n",
      "\t train-loss: 0.57 | valid-loss: 0.663 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 169\n",
      "\t train-loss: 0.562 | valid-loss: 0.647 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 170\n",
      "\t train-loss: 0.56 | valid-loss: 0.84 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 171\n",
      "\t train-loss: 0.552 | valid-loss: 0.676 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 172\n",
      "\t train-loss: 0.552 | valid-loss: 0.627 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 173\n",
      "\t train-loss: 0.566 | valid-loss: 0.631 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 174\n",
      "\t train-loss: 0.583 | valid-loss: 0.626 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 175\n",
      "\t train-loss: 0.571 | valid-loss: 0.734 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 176\n",
      "\t train-loss: 0.552 | valid-loss: 0.631 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 177\n",
      "\t train-loss: 0.548 | valid-loss: 0.614 \t| valid-metric: 0.041 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.041. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 178\n",
      "\t train-loss: 0.541 | valid-loss: 0.621 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 179\n",
      "\t train-loss: 0.539 | valid-loss: 0.608 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 180\n",
      "\t train-loss: 0.538 | valid-loss: 0.694 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 181\n",
      "\t train-loss: 0.535 | valid-loss: 0.629 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 182\n",
      "\t train-loss: 0.536 | valid-loss: 0.674 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 183\n",
      "\t train-loss: 0.545 | valid-loss: 0.62 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 184\n",
      "\t train-loss: 0.56 | valid-loss: 0.763 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 185\n",
      "\t train-loss: 0.536 | valid-loss: 0.618 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 186\n",
      "\t train-loss: 0.536 | valid-loss: 0.609 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 187\n",
      "\t train-loss: 0.537 | valid-loss: 0.634 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 188\n",
      "\t train-loss: 0.539 | valid-loss: 0.609 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 189\n",
      "\t train-loss: 0.546 | valid-loss: 0.604 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 190\n",
      "\t train-loss: 0.545 | valid-loss: 0.59 \t| valid-metric: 0.04 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.04. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 191\n",
      "\t train-loss: 0.55 | valid-loss: 0.621 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 192\n",
      "\t train-loss: 0.537 | valid-loss: 0.596 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 193\n",
      "\t train-loss: 0.529 | valid-loss: 0.677 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 194\n",
      "\t train-loss: 0.533 | valid-loss: 0.944 \t| valid-metric: 0.051 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 195\n",
      "\t train-loss: 0.538 | valid-loss: 0.689 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 196\n",
      "\t train-loss: 0.528 | valid-loss: 0.779 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 197\n",
      "\t train-loss: 0.524 | valid-loss: 0.713 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 198\n",
      "\t train-loss: 0.535 | valid-loss: 0.588 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 199\n",
      "\t train-loss: 0.544 | valid-loss: 0.595 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 200\n",
      "\t train-loss: 0.533 | valid-loss: 0.632 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 201\n",
      "\t train-loss: 0.525 | valid-loss: 0.58 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 202\n",
      "\t train-loss: 0.521 | valid-loss: 0.587 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 203\n",
      "\t train-loss: 0.526 | valid-loss: 0.617 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 204\n",
      "\t train-loss: 0.526 | valid-loss: 0.591 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 205\n",
      "\t train-loss: 0.524 | valid-loss: 0.58 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 206\n",
      "\t train-loss: 0.515 | valid-loss: 0.648 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 207\n",
      "\t train-loss: 0.515 | valid-loss: 0.578 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 208\n",
      "\t train-loss: 0.528 | valid-loss: 0.57 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 209\n",
      "\t train-loss: 0.521 | valid-loss: 0.57 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 210\n",
      "\t train-loss: 0.516 | valid-loss: 0.634 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 211\n",
      "\t train-loss: 0.53 | valid-loss: 0.591 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 212\n",
      "\t train-loss: 0.528 | valid-loss: 0.718 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 213\n",
      "\t train-loss: 0.522 | valid-loss: 0.569 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 214\n",
      "\t train-loss: 0.524 | valid-loss: 0.6 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 215\n",
      "\t train-loss: 0.517 | valid-loss: 0.632 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 216\n",
      "\t train-loss: 0.51 | valid-loss: 0.573 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 217\n",
      "\t train-loss: 0.51 | valid-loss: 0.575 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 218\n",
      "\t train-loss: 0.532 | valid-loss: 0.719 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 219\n",
      "\t train-loss: 0.566 | valid-loss: 0.563 \t| valid-metric: 0.039 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.039. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 220\n",
      "\t train-loss: 0.521 | valid-loss: 0.567 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 221\n",
      "\t train-loss: 0.516 | valid-loss: 0.646 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 222\n",
      "\t train-loss: 0.507 | valid-loss: 0.566 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 223\n",
      "\t train-loss: 0.51 | valid-loss: 0.638 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 224\n",
      "\t train-loss: 0.516 | valid-loss: 0.654 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 225\n",
      "\t train-loss: 0.508 | valid-loss: 0.575 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 226\n",
      "\t train-loss: 0.523 | valid-loss: 0.559 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 227\n",
      "\t train-loss: 0.502 | valid-loss: 0.586 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 228\n",
      "\t train-loss: 0.505 | valid-loss: 0.57 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 229\n",
      "\t train-loss: 0.501 | valid-loss: 0.658 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 230\n",
      "\t train-loss: 0.503 | valid-loss: 0.604 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 231\n",
      "\t train-loss: 0.502 | valid-loss: 0.576 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 232\n",
      "\t train-loss: 0.502 | valid-loss: 0.646 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 233\n",
      "\t train-loss: 0.503 | valid-loss: 0.626 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 234\n",
      "\t train-loss: 0.504 | valid-loss: 0.595 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 235\n",
      "\t train-loss: 0.509 | valid-loss: 0.669 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 236\n",
      "\t train-loss: 0.53 | valid-loss: 0.552 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 237\n",
      "\t train-loss: 0.518 | valid-loss: 0.555 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 238\n",
      "\t train-loss: 0.495 | valid-loss: 0.56 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 239\n",
      "\t train-loss: 0.496 | valid-loss: 0.546 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 240\n",
      "\t train-loss: 0.498 | valid-loss: 0.718 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 241\n",
      "\t train-loss: 0.508 | valid-loss: 0.564 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 242\n",
      "\t train-loss: 0.497 | valid-loss: 0.541 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 243\n",
      "\t train-loss: 0.499 | valid-loss: 0.552 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 244\n",
      "\t train-loss: 0.522 | valid-loss: 0.919 \t| valid-metric: 0.05 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 245\n",
      "\t train-loss: 0.547 | valid-loss: 0.565 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 246\n",
      "\t train-loss: 0.513 | valid-loss: 0.562 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 247\n",
      "\t train-loss: 0.505 | valid-loss: 0.746 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 248\n",
      "\t train-loss: 0.502 | valid-loss: 0.555 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 249\n",
      "\t train-loss: 0.515 | valid-loss: 0.781 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 250\n",
      "\t train-loss: 0.508 | valid-loss: 0.635 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 251\n",
      "\t train-loss: 0.495 | valid-loss: 0.649 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 252\n",
      "\t train-loss: 0.491 | valid-loss: 0.54 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 253\n",
      "\t train-loss: 0.494 | valid-loss: 0.625 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 254\n",
      "\t train-loss: 0.485 | valid-loss: 0.533 \t| valid-metric: 0.038 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.038. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 255\n",
      "\t train-loss: 0.493 | valid-loss: 0.532 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 256\n",
      "\t train-loss: 0.503 | valid-loss: 0.576 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 257\n",
      "\t train-loss: 0.526 | valid-loss: 0.813 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 258\n",
      "\t train-loss: 0.522 | valid-loss: 0.54 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 259\n",
      "\t train-loss: 0.501 | valid-loss: 0.609 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 260\n",
      "\t train-loss: 0.486 | valid-loss: 0.698 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 261\n",
      "\t train-loss: 0.51 | valid-loss: 0.538 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 262\n",
      "\t train-loss: 0.497 | valid-loss: 0.548 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 263\n",
      "\t train-loss: 0.495 | valid-loss: 0.522 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 264\n",
      "\t train-loss: 0.488 | valid-loss: 0.527 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 265\n",
      "\t train-loss: 0.504 | valid-loss: 0.619 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 266\n",
      "\t train-loss: 0.504 | valid-loss: 0.528 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 267\n",
      "\t train-loss: 0.481 | valid-loss: 0.547 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 268\n",
      "\t train-loss: 0.482 | valid-loss: 0.626 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 269\n",
      "\t train-loss: 0.479 | valid-loss: 0.598 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 270\n",
      "\t train-loss: 0.481 | valid-loss: 0.55 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 271\n",
      "\t train-loss: 0.48 | valid-loss: 0.566 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 272\n",
      "\t train-loss: 0.482 | valid-loss: 0.529 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 273\n",
      "\t train-loss: 0.509 | valid-loss: 0.517 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 274\n",
      "\t train-loss: 0.495 | valid-loss: 0.523 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 275\n",
      "\t train-loss: 0.497 | valid-loss: 0.528 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 276\n",
      "\t train-loss: 0.504 | valid-loss: 0.545 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 277\n",
      "\t train-loss: 0.473 | valid-loss: 0.531 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 278\n",
      "\t train-loss: 0.482 | valid-loss: 0.541 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 279\n",
      "\t train-loss: 0.474 | valid-loss: 0.517 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 280\n",
      "\t train-loss: 0.471 | valid-loss: 0.528 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 281\n",
      "\t train-loss: 0.475 | valid-loss: 0.516 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 282\n",
      "\t train-loss: 0.473 | valid-loss: 0.521 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 283\n",
      "\t train-loss: 0.49 | valid-loss: 0.576 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 284\n",
      "\t train-loss: 0.491 | valid-loss: 0.537 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 285\n",
      "\t train-loss: 0.487 | valid-loss: 0.588 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 286\n",
      "\t train-loss: 0.508 | valid-loss: 0.75 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 287\n",
      "\t train-loss: 0.477 | valid-loss: 0.553 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 288\n",
      "\t train-loss: 0.469 | valid-loss: 0.512 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 289\n",
      "\t train-loss: 0.467 | valid-loss: 0.517 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 290\n",
      "\t train-loss: 0.476 | valid-loss: 0.651 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 291\n",
      "\t train-loss: 0.499 | valid-loss: 0.635 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 292\n",
      "\t train-loss: 0.507 | valid-loss: 0.517 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 293\n",
      "\t train-loss: 0.468 | valid-loss: 0.52 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 294\n",
      "\t train-loss: 0.468 | valid-loss: 0.561 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 295\n",
      "\t train-loss: 0.478 | valid-loss: 0.605 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 296\n",
      "\t train-loss: 0.466 | valid-loss: 0.557 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 297\n",
      "\t train-loss: 0.469 | valid-loss: 0.616 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 298\n",
      "\t train-loss: 0.488 | valid-loss: 0.509 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 299\n",
      "\t train-loss: 0.47 | valid-loss: 0.512 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 300\n",
      "\t train-loss: 0.468 | valid-loss: 0.538 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 301\n",
      "\t train-loss: 0.463 | valid-loss: 0.511 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 302\n",
      "\t train-loss: 0.475 | valid-loss: 0.503 \t| valid-metric: 0.037 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.037. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 303\n",
      "\t train-loss: 0.462 | valid-loss: 0.506 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 304\n",
      "\t train-loss: 0.466 | valid-loss: 0.787 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 305\n",
      "\t train-loss: 0.542 | valid-loss: 0.701 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 306\n",
      "\t train-loss: 0.508 | valid-loss: 0.54 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 307\n",
      "\t train-loss: 0.462 | valid-loss: 0.5 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 308\n",
      "\t train-loss: 0.466 | valid-loss: 0.51 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 309\n",
      "\t train-loss: 0.462 | valid-loss: 0.499 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 310\n",
      "\t train-loss: 0.456 | valid-loss: 0.508 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 311\n",
      "\t train-loss: 0.46 | valid-loss: 0.612 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 312\n",
      "\t train-loss: 0.475 | valid-loss: 0.502 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 313\n",
      "\t train-loss: 0.475 | valid-loss: 0.501 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 314\n",
      "\t train-loss: 0.465 | valid-loss: 0.541 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 315\n",
      "\t train-loss: 0.457 | valid-loss: 0.517 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 316\n",
      "\t train-loss: 0.462 | valid-loss: 0.506 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 317\n",
      "\t train-loss: 0.453 | valid-loss: 0.511 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 318\n",
      "\t train-loss: 0.454 | valid-loss: 0.509 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 319\n",
      "\t train-loss: 0.452 | valid-loss: 0.555 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 320\n",
      "\t train-loss: 0.456 | valid-loss: 0.525 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 321\n",
      "\t train-loss: 0.459 | valid-loss: 0.5 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 322\n",
      "\t train-loss: 0.454 | valid-loss: 0.505 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 323\n",
      "\t train-loss: 0.451 | valid-loss: 0.505 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 324\n",
      "\t train-loss: 0.457 | valid-loss: 0.488 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 325\n",
      "\t train-loss: 0.46 | valid-loss: 0.536 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 326\n",
      "\t train-loss: 0.473 | valid-loss: 0.52 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 327\n",
      "\t train-loss: 0.467 | valid-loss: 0.533 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 328\n",
      "\t train-loss: 0.455 | valid-loss: 0.517 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 329\n",
      "\t train-loss: 0.452 | valid-loss: 0.548 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 330\n",
      "\t train-loss: 0.452 | valid-loss: 0.578 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 331\n",
      "\t train-loss: 0.454 | valid-loss: 0.691 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 332\n",
      "\t train-loss: 0.455 | valid-loss: 0.61 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 333\n",
      "\t train-loss: 0.473 | valid-loss: 0.551 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 334\n",
      "\t train-loss: 0.467 | valid-loss: 0.565 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 335\n",
      "\t train-loss: 0.448 | valid-loss: 0.537 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 336\n",
      "\t train-loss: 0.455 | valid-loss: 0.491 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 337\n",
      "\t train-loss: 0.474 | valid-loss: 0.51 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 338\n",
      "\t train-loss: 0.486 | valid-loss: 0.774 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 339\n",
      "\t train-loss: 0.473 | valid-loss: 0.48 \t| valid-metric: 0.036 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.036. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 340\n",
      "\t train-loss: 0.457 | valid-loss: 0.491 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 341\n",
      "\t train-loss: 0.482 | valid-loss: 0.88 \t| valid-metric: 0.049 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 342\n",
      "\t train-loss: 0.465 | valid-loss: 0.484 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 343\n",
      "\t train-loss: 0.444 | valid-loss: 0.539 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 344\n",
      "\t train-loss: 0.451 | valid-loss: 0.511 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 345\n",
      "\t train-loss: 0.446 | valid-loss: 0.61 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 346\n",
      "\t train-loss: 0.447 | valid-loss: 0.48 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 347\n",
      "\t train-loss: 0.455 | valid-loss: 0.504 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 348\n",
      "\t train-loss: 0.459 | valid-loss: 0.486 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 349\n",
      "\t train-loss: 0.454 | valid-loss: 0.543 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 350\n",
      "\t train-loss: 0.443 | valid-loss: 0.589 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 351\n",
      "\t train-loss: 0.44 | valid-loss: 0.478 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 352\n",
      "\t train-loss: 0.445 | valid-loss: 0.498 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 353\n",
      "\t train-loss: 0.451 | valid-loss: 0.583 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 354\n",
      "\t train-loss: 0.45 | valid-loss: 0.475 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 355\n",
      "\t train-loss: 0.442 | valid-loss: 0.476 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 356\n",
      "\t train-loss: 0.438 | valid-loss: 0.514 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 357\n",
      "\t train-loss: 0.454 | valid-loss: 0.494 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 358\n",
      "\t train-loss: 0.47 | valid-loss: 0.695 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 359\n",
      "\t train-loss: 0.45 | valid-loss: 0.488 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 360\n",
      "\t train-loss: 0.449 | valid-loss: 0.489 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 361\n",
      "\t train-loss: 0.454 | valid-loss: 0.76 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 362\n",
      "\t train-loss: 0.442 | valid-loss: 0.503 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 363\n",
      "\t train-loss: 0.445 | valid-loss: 0.707 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 364\n",
      "\t train-loss: 0.467 | valid-loss: 0.478 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 365\n",
      "\t train-loss: 0.439 | valid-loss: 0.468 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 366\n",
      "\t train-loss: 0.451 | valid-loss: 0.638 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 367\n",
      "\t train-loss: 0.442 | valid-loss: 0.553 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 368\n",
      "\t train-loss: 0.435 | valid-loss: 0.503 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 369\n",
      "\t train-loss: 0.44 | valid-loss: 0.503 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 370\n",
      "\t train-loss: 0.447 | valid-loss: 0.631 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 371\n",
      "\t train-loss: 0.455 | valid-loss: 0.505 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 372\n",
      "\t train-loss: 0.439 | valid-loss: 0.467 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 373\n",
      "\t train-loss: 0.438 | valid-loss: 0.634 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 374\n",
      "\t train-loss: 0.461 | valid-loss: 0.468 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 375\n",
      "\t train-loss: 0.47 | valid-loss: 0.479 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 376\n",
      "\t train-loss: 0.44 | valid-loss: 0.484 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 377\n",
      "\t train-loss: 0.437 | valid-loss: 0.513 \t| valid-metric: 0.038 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 378\n",
      "\t train-loss: 0.438 | valid-loss: 0.481 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 379\n",
      "\t train-loss: 0.448 | valid-loss: 0.472 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 380\n",
      "\t train-loss: 0.443 | valid-loss: 0.482 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 381\n",
      "\t train-loss: 0.432 | valid-loss: 0.466 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 382\n",
      "\t train-loss: 0.445 | valid-loss: 0.461 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 383\n",
      "\t train-loss: 0.437 | valid-loss: 0.605 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 384\n",
      "\t train-loss: 0.432 | valid-loss: 0.46 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 385\n",
      "\t train-loss: 0.436 | valid-loss: 0.463 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 386\n",
      "\t train-loss: 0.433 | valid-loss: 0.463 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 387\n",
      "\t train-loss: 0.435 | valid-loss: 0.467 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 388\n",
      "\t train-loss: 0.429 | valid-loss: 0.589 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 389\n",
      "\t train-loss: 0.431 | valid-loss: 0.475 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 390\n",
      "\t train-loss: 0.428 | valid-loss: 0.483 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 391\n",
      "\t train-loss: 0.43 | valid-loss: 0.561 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 392\n",
      "\t train-loss: 0.431 | valid-loss: 0.465 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 393\n",
      "\t train-loss: 0.426 | valid-loss: 0.483 \t| valid-metric: 0.037 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 394\n",
      "\t train-loss: 0.434 | valid-loss: 0.468 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 395\n",
      "\t train-loss: 0.428 | valid-loss: 0.457 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 396\n",
      "\t train-loss: 0.441 | valid-loss: 0.547 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 397\n",
      "\t train-loss: 0.435 | valid-loss: 0.454 \t| valid-metric: 0.035 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.035. Saving model...\n",
      "\n",
      "Iter 2\n",
      " Epoch 398\n",
      "\t train-loss: 0.436 | valid-loss: 0.463 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Iter 2\n",
      " Epoch 399\n",
      "\t train-loss: 0.453 | valid-loss: 0.457 \t| valid-metric: 0.036 | lr: 0.01\n",
      "Training is finished.\n",
      "Best model was at epoch: 397\n",
      "[[0.3464, 0.3576, 0.3807, 0.4105, 0.4429], [0.038, 0.1199, 0.2076, 0.289, 0.3627], [0.042, 0.1226, 0.2102, 0.2917, 0.3656]]\n",
      "**************************************************************************************************** iter: 3****************************************************************************************************\n",
      "CITRUS(\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "  (encoder): Linear(in_features=5, out_features=4, bias=True)\n",
      "  (CPGNN): CPGNN_ST_in_TTS(\n",
      "    (last_activation): LeakyReLU(negative_slope=0.01)\n",
      "    (first_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (last_lin): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (merge_lin): Linear(in_features=1090, out_features=1, bias=True)\n",
      "    (node_embeddings): NodeEmbedding(n_nodes=109, embedding_size=4)\n",
      "    (block_0): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_1): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (block_2): CPGNN_block_v2(\n",
      "      (channel_mixer): Linear(in_features=4, out_features=4, bias=True)\n",
      "      (diff_derivative): Time_derivative_diffusion_product(\n",
      "        (Conv_layer): GCN_diff(\n",
      "          (conv1): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "      (mlp): MiniMLP(\n",
      "        (miniMLP_mlp_layer_000): Linear(in_features=8, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_000): ReLU()\n",
      "        (miniMLP_mlp_layer_001): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_001): ReLU()\n",
      "        (miniMLP_mlp_layer_002): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_002): ReLU()\n",
      "        (miniMLP_mlp_layer_003): Linear(in_features=4, out_features=4, bias=True)\n",
      "        (miniMLP_mlp_act_003): ReLU()\n",
      "        (miniMLP_mlp_layer_004): Linear(in_features=4, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=1)\n",
      ")\n",
      "Number of parameters: 2544.0\n",
      "11 batches per epoch (3051 trn samples in total | batch_size: 256)\n",
      "Iter 3\n",
      " Epoch 0\n",
      "\t train-loss: 123.854 | valid-loss: 135.442 \t| valid-metric: 0.613 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.613. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 1\n",
      "\t train-loss: 57.207 | valid-loss: 147.904 \t| valid-metric: 0.64 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 2\n",
      "\t train-loss: 47.465 | valid-loss: 130.286 \t| valid-metric: 0.601 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.601. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 3\n",
      "\t train-loss: 41.461 | valid-loss: 87.843 \t| valid-metric: 0.493 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.493. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 4\n",
      "\t train-loss: 37.656 | valid-loss: 82.554 \t| valid-metric: 0.478 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.478. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 5\n",
      "\t train-loss: 34.642 | valid-loss: 79.323 \t| valid-metric: 0.469 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.469. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 6\n",
      "\t train-loss: 32.066 | valid-loss: 66.3 \t| valid-metric: 0.429 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.429. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 7\n",
      "\t train-loss: 29.639 | valid-loss: 63.052 \t| valid-metric: 0.418 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.418. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 8\n",
      "\t train-loss: 27.654 | valid-loss: 63.469 \t| valid-metric: 0.419 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 9\n",
      "\t train-loss: 25.826 | valid-loss: 54.334 \t| valid-metric: 0.388 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.388. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 10\n",
      "\t train-loss: 24.188 | valid-loss: 63.448 \t| valid-metric: 0.419 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 11\n",
      "\t train-loss: 22.777 | valid-loss: 47.08 \t| valid-metric: 0.361 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.361. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 12\n",
      "\t train-loss: 21.481 | valid-loss: 47.98 \t| valid-metric: 0.365 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 13\n",
      "\t train-loss: 20.252 | valid-loss: 45.796 \t| valid-metric: 0.356 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.356. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 14\n",
      "\t train-loss: 19.132 | valid-loss: 49.383 \t| valid-metric: 0.37 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 15\n",
      "\t train-loss: 18.142 | valid-loss: 42.144 \t| valid-metric: 0.342 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.342. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 16\n",
      "\t train-loss: 17.167 | valid-loss: 43.113 \t| valid-metric: 0.346 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 17\n",
      "\t train-loss: 16.274 | valid-loss: 38.788 \t| valid-metric: 0.328 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.328. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 18\n",
      "\t train-loss: 15.334 | valid-loss: 38.794 \t| valid-metric: 0.328 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 19\n",
      "\t train-loss: 14.387 | valid-loss: 32.675 \t| valid-metric: 0.301 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.301. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 20\n",
      "\t train-loss: 13.117 | valid-loss: 28.744 \t| valid-metric: 0.282 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.282. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 21\n",
      "\t train-loss: 11.403 | valid-loss: 20.428 \t| valid-metric: 0.238 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.238. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 22\n",
      "\t train-loss: 10.155 | valid-loss: 21.894 \t| valid-metric: 0.246 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 23\n",
      "\t train-loss: 9.054 | valid-loss: 30.72 \t| valid-metric: 0.292 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 24\n",
      "\t train-loss: 8.173 | valid-loss: 22.731 \t| valid-metric: 0.251 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 25\n",
      "\t train-loss: 7.47 | valid-loss: 18.7 \t| valid-metric: 0.228 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.228. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 26\n",
      "\t train-loss: 6.774 | valid-loss: 22.455 \t| valid-metric: 0.249 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 27\n",
      "\t train-loss: 6.278 | valid-loss: 20.27 \t| valid-metric: 0.237 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 28\n",
      "\t train-loss: 5.868 | valid-loss: 15.253 \t| valid-metric: 0.206 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.206. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 29\n",
      "\t train-loss: 5.49 | valid-loss: 16.899 \t| valid-metric: 0.216 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 30\n",
      "\t train-loss: 5.143 | valid-loss: 14.173 \t| valid-metric: 0.198 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.198. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 31\n",
      "\t train-loss: 4.768 | valid-loss: 14.472 \t| valid-metric: 0.2 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 32\n",
      "\t train-loss: 4.451 | valid-loss: 15.712 \t| valid-metric: 0.209 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 33\n",
      "\t train-loss: 4.265 | valid-loss: 12.326 \t| valid-metric: 0.185 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.185. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 34\n",
      "\t train-loss: 3.962 | valid-loss: 15.246 \t| valid-metric: 0.206 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 35\n",
      "\t train-loss: 3.696 | valid-loss: 9.97 \t| valid-metric: 0.166 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.166. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 36\n",
      "\t train-loss: 3.433 | valid-loss: 10.464 \t| valid-metric: 0.17 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 37\n",
      "\t train-loss: 3.272 | valid-loss: 10.917 \t| valid-metric: 0.174 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 38\n",
      "\t train-loss: 3.101 | valid-loss: 10.579 \t| valid-metric: 0.171 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 39\n",
      "\t train-loss: 2.916 | valid-loss: 8.239 \t| valid-metric: 0.151 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.151. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 40\n",
      "\t train-loss: 2.749 | valid-loss: 9.662 \t| valid-metric: 0.164 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 41\n",
      "\t train-loss: 2.604 | valid-loss: 10.766 \t| valid-metric: 0.173 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 42\n",
      "\t train-loss: 2.477 | valid-loss: 6.74 \t| valid-metric: 0.137 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.137. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 43\n",
      "\t train-loss: 2.324 | valid-loss: 7.819 \t| valid-metric: 0.147 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 44\n",
      "\t train-loss: 2.189 | valid-loss: 6.863 \t| valid-metric: 0.138 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 45\n",
      "\t train-loss: 2.068 | valid-loss: 6.744 \t| valid-metric: 0.137 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 46\n",
      "\t train-loss: 1.963 | valid-loss: 6.586 \t| valid-metric: 0.135 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.135. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 47\n",
      "\t train-loss: 1.864 | valid-loss: 5.911 \t| valid-metric: 0.128 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.128. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 48\n",
      "\t train-loss: 1.782 | valid-loss: 5.291 \t| valid-metric: 0.121 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.121. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 49\n",
      "\t train-loss: 1.718 | valid-loss: 5.509 \t| valid-metric: 0.124 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 50\n",
      "\t train-loss: 1.634 | valid-loss: 4.616 \t| valid-metric: 0.113 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.113. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 51\n",
      "\t train-loss: 1.573 | valid-loss: 4.037 \t| valid-metric: 0.106 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.106. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 52\n",
      "\t train-loss: 1.515 | valid-loss: 4.027 \t| valid-metric: 0.106 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 53\n",
      "\t train-loss: 1.462 | valid-loss: 3.302 \t| valid-metric: 0.096 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.096. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 54\n",
      "\t train-loss: 1.424 | valid-loss: 3.953 \t| valid-metric: 0.105 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 55\n",
      "\t train-loss: 1.407 | valid-loss: 2.992 \t| valid-metric: 0.091 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.091. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 56\n",
      "\t train-loss: 1.355 | valid-loss: 2.529 \t| valid-metric: 0.084 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.084. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 57\n",
      "\t train-loss: 1.325 | valid-loss: 2.841 \t| valid-metric: 0.089 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 58\n",
      "\t train-loss: 1.309 | valid-loss: 2.561 \t| valid-metric: 0.084 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 59\n",
      "\t train-loss: 1.284 | valid-loss: 2.086 \t| valid-metric: 0.076 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.076. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 60\n",
      "\t train-loss: 1.27 | valid-loss: 2.665 \t| valid-metric: 0.086 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 61\n",
      "\t train-loss: 1.242 | valid-loss: 2.983 \t| valid-metric: 0.091 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 62\n",
      "\t train-loss: 1.227 | valid-loss: 2.621 \t| valid-metric: 0.085 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 63\n",
      "\t train-loss: 1.205 | valid-loss: 2.292 \t| valid-metric: 0.08 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 64\n",
      "\t train-loss: 1.185 | valid-loss: 2.189 \t| valid-metric: 0.078 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 65\n",
      "\t train-loss: 1.181 | valid-loss: 1.972 \t| valid-metric: 0.074 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.074. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 66\n",
      "\t train-loss: 1.153 | valid-loss: 2.143 \t| valid-metric: 0.077 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 67\n",
      "\t train-loss: 1.13 | valid-loss: 2.061 \t| valid-metric: 0.076 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 68\n",
      "\t train-loss: 1.13 | valid-loss: 1.851 \t| valid-metric: 0.072 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.072. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 69\n",
      "\t train-loss: 1.105 | valid-loss: 2.003 \t| valid-metric: 0.074 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 70\n",
      "\t train-loss: 1.08 | valid-loss: 2.016 \t| valid-metric: 0.075 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 71\n",
      "\t train-loss: 1.065 | valid-loss: 1.936 \t| valid-metric: 0.073 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 72\n",
      "\t train-loss: 1.063 | valid-loss: 2.049 \t| valid-metric: 0.075 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 73\n",
      "\t train-loss: 1.047 | valid-loss: 2.171 \t| valid-metric: 0.078 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 74\n",
      "\t train-loss: 1.027 | valid-loss: 1.78 \t| valid-metric: 0.07 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.07. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 75\n",
      "\t train-loss: 1.022 | valid-loss: 1.526 \t| valid-metric: 0.065 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.065. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 76\n",
      "\t train-loss: 1.015 | valid-loss: 1.721 \t| valid-metric: 0.069 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 77\n",
      "\t train-loss: 1.003 | valid-loss: 1.621 \t| valid-metric: 0.067 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 78\n",
      "\t train-loss: 0.978 | valid-loss: 1.752 \t| valid-metric: 0.07 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 79\n",
      "\t train-loss: 0.967 | valid-loss: 2.048 \t| valid-metric: 0.075 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 80\n",
      "\t train-loss: 0.945 | valid-loss: 1.828 \t| valid-metric: 0.071 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 81\n",
      "\t train-loss: 0.933 | valid-loss: 1.55 \t| valid-metric: 0.066 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 82\n",
      "\t train-loss: 0.915 | valid-loss: 1.424 \t| valid-metric: 0.063 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.063. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 83\n",
      "\t train-loss: 0.911 | valid-loss: 1.421 \t| valid-metric: 0.063 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 84\n",
      "\t train-loss: 0.89 | valid-loss: 1.379 \t| valid-metric: 0.062 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.062. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 85\n",
      "\t train-loss: 0.875 | valid-loss: 1.497 \t| valid-metric: 0.064 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 86\n",
      "\t train-loss: 0.885 | valid-loss: 1.559 \t| valid-metric: 0.066 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 87\n",
      "\t train-loss: 0.87 | valid-loss: 1.642 \t| valid-metric: 0.067 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 88\n",
      "\t train-loss: 0.849 | valid-loss: 1.381 \t| valid-metric: 0.062 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 89\n",
      "\t train-loss: 0.834 | valid-loss: 1.346 \t| valid-metric: 0.061 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.061. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 90\n",
      "\t train-loss: 0.824 | valid-loss: 1.268 \t| valid-metric: 0.059 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.059. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 91\n",
      "\t train-loss: 0.809 | valid-loss: 1.259 \t| valid-metric: 0.059 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 92\n",
      "\t train-loss: 0.802 | valid-loss: 1.238 \t| valid-metric: 0.059 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 93\n",
      "\t train-loss: 0.813 | valid-loss: 1.269 \t| valid-metric: 0.059 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 94\n",
      "\t train-loss: 0.796 | valid-loss: 1.241 \t| valid-metric: 0.059 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 95\n",
      "\t train-loss: 0.774 | valid-loss: 1.204 \t| valid-metric: 0.058 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.058. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 96\n",
      "\t train-loss: 0.76 | valid-loss: 1.142 \t| valid-metric: 0.056 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.056. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 97\n",
      "\t train-loss: 0.762 | valid-loss: 1.271 \t| valid-metric: 0.059 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 98\n",
      "\t train-loss: 0.741 | valid-loss: 1.151 \t| valid-metric: 0.056 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 99\n",
      "\t train-loss: 0.732 | valid-loss: 1.132 \t| valid-metric: 0.056 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 100\n",
      "\t train-loss: 0.738 | valid-loss: 1.092 \t| valid-metric: 0.055 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.055. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 101\n",
      "\t train-loss: 0.747 | valid-loss: 1.094 \t| valid-metric: 0.055 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 102\n",
      "\t train-loss: 0.73 | valid-loss: 1.394 \t| valid-metric: 0.062 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 103\n",
      "\t train-loss: 0.732 | valid-loss: 1.232 \t| valid-metric: 0.058 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 104\n",
      "\t train-loss: 0.717 | valid-loss: 1.086 \t| valid-metric: 0.055 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 105\n",
      "\t train-loss: 0.697 | valid-loss: 1.129 \t| valid-metric: 0.056 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 106\n",
      "\t train-loss: 0.685 | valid-loss: 1.212 \t| valid-metric: 0.058 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 107\n",
      "\t train-loss: 0.68 | valid-loss: 1.214 \t| valid-metric: 0.058 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 108\n",
      "\t train-loss: 0.686 | valid-loss: 0.971 \t| valid-metric: 0.052 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.052. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 109\n",
      "\t train-loss: 0.702 | valid-loss: 0.948 \t| valid-metric: 0.051 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.051. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 110\n",
      "\t train-loss: 0.671 | valid-loss: 1.369 \t| valid-metric: 0.062 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 111\n",
      "\t train-loss: 0.667 | valid-loss: 1.102 \t| valid-metric: 0.055 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 112\n",
      "\t train-loss: 0.643 | valid-loss: 1.135 \t| valid-metric: 0.056 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 113\n",
      "\t train-loss: 0.644 | valid-loss: 1.021 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 114\n",
      "\t train-loss: 0.655 | valid-loss: 1.228 \t| valid-metric: 0.058 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 115\n",
      "\t train-loss: 0.64 | valid-loss: 1.138 \t| valid-metric: 0.056 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 116\n",
      "\t train-loss: 0.618 | valid-loss: 0.979 \t| valid-metric: 0.052 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 117\n",
      "\t train-loss: 0.613 | valid-loss: 0.961 \t| valid-metric: 0.052 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 118\n",
      "\t train-loss: 0.611 | valid-loss: 1.03 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 119\n",
      "\t train-loss: 0.621 | valid-loss: 0.969 \t| valid-metric: 0.052 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 120\n",
      "\t train-loss: 0.598 | valid-loss: 1.02 \t| valid-metric: 0.053 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 121\n",
      "\t train-loss: 0.602 | valid-loss: 0.84 \t| valid-metric: 0.048 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.048. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 122\n",
      "\t train-loss: 0.619 | valid-loss: 0.891 \t| valid-metric: 0.05 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 123\n",
      "\t train-loss: 0.593 | valid-loss: 0.806 \t| valid-metric: 0.047 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.047. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 124\n",
      "\t train-loss: 0.58 | valid-loss: 0.812 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 125\n",
      "\t train-loss: 0.606 | valid-loss: 0.994 \t| valid-metric: 0.052 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 126\n",
      "\t train-loss: 0.585 | valid-loss: 0.828 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 127\n",
      "\t train-loss: 0.579 | valid-loss: 0.842 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 128\n",
      "\t train-loss: 0.571 | valid-loss: 0.783 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 129\n",
      "\t train-loss: 0.562 | valid-loss: 0.851 \t| valid-metric: 0.049 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 130\n",
      "\t train-loss: 0.563 | valid-loss: 0.908 \t| valid-metric: 0.05 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 131\n",
      "\t train-loss: 0.559 | valid-loss: 0.773 \t| valid-metric: 0.046 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.046. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 132\n",
      "\t train-loss: 0.559 | valid-loss: 0.757 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 133\n",
      "\t train-loss: 0.576 | valid-loss: 0.793 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 134\n",
      "\t train-loss: 0.565 | valid-loss: 0.746 \t| valid-metric: 0.045 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.045. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 135\n",
      "\t train-loss: 0.554 | valid-loss: 0.724 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 136\n",
      "\t train-loss: 0.553 | valid-loss: 0.734 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 137\n",
      "\t train-loss: 0.557 | valid-loss: 0.734 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 138\n",
      "\t train-loss: 0.539 | valid-loss: 0.725 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 139\n",
      "\t train-loss: 0.534 | valid-loss: 0.724 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 140\n",
      "\t train-loss: 0.524 | valid-loss: 0.863 \t| valid-metric: 0.049 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 141\n",
      "\t train-loss: 0.523 | valid-loss: 0.797 \t| valid-metric: 0.047 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 142\n",
      "\t train-loss: 0.519 | valid-loss: 0.734 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 143\n",
      "\t train-loss: 0.526 | valid-loss: 0.709 \t| valid-metric: 0.044 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.044. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 144\n",
      "\t train-loss: 0.518 | valid-loss: 0.684 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 145\n",
      "\t train-loss: 0.517 | valid-loss: 0.699 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 146\n",
      "\t train-loss: 0.51 | valid-loss: 0.712 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 147\n",
      "\t train-loss: 0.507 | valid-loss: 0.679 \t| valid-metric: 0.043 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.043. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 148\n",
      "\t train-loss: 0.499 | valid-loss: 0.765 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 149\n",
      "\t train-loss: 0.503 | valid-loss: 0.763 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 150\n",
      "\t train-loss: 0.546 | valid-loss: 0.708 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 151\n",
      "\t train-loss: 0.511 | valid-loss: 0.653 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 152\n",
      "\t train-loss: 0.517 | valid-loss: 0.658 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 153\n",
      "\t train-loss: 0.53 | valid-loss: 0.873 \t| valid-metric: 0.049 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 154\n",
      "\t train-loss: 0.525 | valid-loss: 0.663 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 155\n",
      "\t train-loss: 0.495 | valid-loss: 0.638 \t| valid-metric: 0.042 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.042. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 156\n",
      "\t train-loss: 0.495 | valid-loss: 0.635 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 157\n",
      "\t train-loss: 0.487 | valid-loss: 0.66 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 158\n",
      "\t train-loss: 0.488 | valid-loss: 0.647 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 159\n",
      "\t train-loss: 0.499 | valid-loss: 0.721 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 160\n",
      "\t train-loss: 0.482 | valid-loss: 0.622 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 161\n",
      "\t train-loss: 0.481 | valid-loss: 0.663 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 162\n",
      "\t train-loss: 0.477 | valid-loss: 0.654 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 163\n",
      "\t train-loss: 0.478 | valid-loss: 0.702 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 164\n",
      "\t train-loss: 0.476 | valid-loss: 0.688 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 165\n",
      "\t train-loss: 0.472 | valid-loss: 0.652 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 166\n",
      "\t train-loss: 0.468 | valid-loss: 0.625 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 167\n",
      "\t train-loss: 0.482 | valid-loss: 0.654 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 168\n",
      "\t train-loss: 0.476 | valid-loss: 0.616 \t| valid-metric: 0.041 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.041. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 169\n",
      "\t train-loss: 0.478 | valid-loss: 0.689 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 170\n",
      "\t train-loss: 0.47 | valid-loss: 0.595 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 171\n",
      "\t train-loss: 0.484 | valid-loss: 0.592 \t| valid-metric: 0.04 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.04. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 172\n",
      "\t train-loss: 0.479 | valid-loss: 0.752 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 173\n",
      "\t train-loss: 0.478 | valid-loss: 0.633 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 174\n",
      "\t train-loss: 0.467 | valid-loss: 0.644 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 175\n",
      "\t train-loss: 0.466 | valid-loss: 0.726 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 176\n",
      "\t train-loss: 0.48 | valid-loss: 0.702 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 177\n",
      "\t train-loss: 0.464 | valid-loss: 0.602 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 178\n",
      "\t train-loss: 0.47 | valid-loss: 0.817 \t| valid-metric: 0.048 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 179\n",
      "\t train-loss: 0.497 | valid-loss: 0.63 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 180\n",
      "\t train-loss: 0.471 | valid-loss: 0.578 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 181\n",
      "\t train-loss: 0.47 | valid-loss: 0.607 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 182\n",
      "\t train-loss: 0.466 | valid-loss: 0.764 \t| valid-metric: 0.046 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 183\n",
      "\t train-loss: 0.456 | valid-loss: 0.58 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 184\n",
      "\t train-loss: 0.452 | valid-loss: 0.662 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 185\n",
      "\t train-loss: 0.475 | valid-loss: 0.725 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 186\n",
      "\t train-loss: 0.461 | valid-loss: 0.569 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 187\n",
      "\t train-loss: 0.475 | valid-loss: 0.654 \t| valid-metric: 0.043 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 188\n",
      "\t train-loss: 0.476 | valid-loss: 0.717 \t| valid-metric: 0.045 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 189\n",
      "\t train-loss: 0.465 | valid-loss: 0.693 \t| valid-metric: 0.044 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 190\n",
      "\t train-loss: 0.466 | valid-loss: 0.558 \t| valid-metric: 0.039 | lr: 0.01\n",
      "\n",
      "\t\t\t\tNew best val_metric: 0.039. Saving model...\n",
      "\n",
      "Iter 3\n",
      " Epoch 191\n",
      "\t train-loss: 0.456 | valid-loss: 0.557 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 192\n",
      "\t train-loss: 0.453 | valid-loss: 0.612 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 193\n",
      "\t train-loss: 0.468 | valid-loss: 0.574 \t| valid-metric: 0.04 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 194\n",
      "\t train-loss: 0.46 | valid-loss: 0.541 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 195\n",
      "\t train-loss: 0.45 | valid-loss: 0.617 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 196\n",
      "\t train-loss: 0.461 | valid-loss: 0.549 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 197\n",
      "\t train-loss: 0.47 | valid-loss: 0.885 \t| valid-metric: 0.05 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 198\n",
      "\t train-loss: 0.46 | valid-loss: 0.634 \t| valid-metric: 0.042 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 199\n",
      "\t train-loss: 0.449 | valid-loss: 0.614 \t| valid-metric: 0.041 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 200\n",
      "\t train-loss: 0.444 | valid-loss: 0.543 \t| valid-metric: 0.039 | lr: 0.01\n",
      "Iter 3\n",
      " Epoch 201\n",
      "\t train-loss: 0.443 | valid-loss: 0.545 \t| valid-metric: 0.039 | lr: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(one_step_gtcnn\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     43\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(optimizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience, factor\u001b[38;5;241m=\u001b[39mfactor)\n\u001b[0;32m---> 45\u001b[0m best_model, best_epoch \u001b[38;5;241m=\u001b[39m train_model_regression(Iter\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m     46\u001b[0m     model\u001b[38;5;241m=\u001b[39mone_step_gtcnn,\n\u001b[1;32m     47\u001b[0m     training_data\u001b[38;5;241m=\u001b[39mtrn_data, validation_data\u001b[38;5;241m=\u001b[39mval_data,  \u001b[38;5;66;03m# [n_samples x 1 x nodes x timesteps]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     single_step_trn_labels\u001b[38;5;241m=\u001b[39mone_step_trn_labels, single_step_val_labels\u001b[38;5;241m=\u001b[39mone_step_val_labels,  \u001b[38;5;66;03m# [n_samples x spatial_nodes]\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     50\u001b[0m     loss_criterion\u001b[38;5;241m=\u001b[39mloss_criterion, optimizer\u001b[38;5;241m=\u001b[39moptimizer, scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m     51\u001b[0m     val_metric_criterion\u001b[38;5;241m=\u001b[39mval_metric,\n\u001b[1;32m     52\u001b[0m     log_dir\u001b[38;5;241m=\u001b[39mlog_dir,\n\u001b[1;32m     53\u001b[0m     not_learning_limit\u001b[38;5;241m=\u001b[39mnot_learning_limit\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m rNMSE_dict, predictions_dict \u001b[38;5;241m=\u001b[39m compute_iteration_rNMSE(best_model, steps_ahead, tst_data_deltas, tst_labels_deltas,\n\u001b[1;32m     57\u001b[0m                                                        device, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m res_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mround\u001b[39m(l\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(rNMSE_dict\u001b[38;5;241m.\u001b[39mvalues())])\n",
      "File \u001b[0;32m~/Documents/Papers/CGP-GNN/2023_TIDE: Time Derivative Diffusion for Deep Learning on Graphs/CPGNN_our_Imp/Final_Sent_Codes2/NOAA/train_utils.py:46\u001b[0m, in \u001b[0;36mtrain_model_regression\u001b[0;34m(Iter, model, training_data, validation_data, single_step_trn_labels, single_step_val_labels, num_epochs, batch_size, loss_criterion, optimizer, scheduler, val_metric_criterion, log_dir, not_learning_limit)\u001b[0m\n\u001b[1;32m     44\u001b[0m     one_step_pred_trn \u001b[38;5;241m=\u001b[39m model(batch_trn_data, h0)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     one_step_pred_trn \u001b[38;5;241m=\u001b[39m model(batch_trn_data)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# obtain the loss function\u001b[39;00m\n\u001b[1;32m     49\u001b[0m batch_trn_loss \u001b[38;5;241m=\u001b[39m loss_criterion(one_step_pred_trn, batch_one_step_trn_labels)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Papers/CGP-GNN/2023_TIDE: Time Derivative Diffusion for Deep Learning on Graphs/CPGNN_our_Imp/Final_Sent_Codes2/NOAA/layers.py:1301\u001b[0m, in \u001b[0;36mCITRUS.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1296\u001b[0m x_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x_emb)  \u001b[38;5;66;03m# linear proj: x_enc = [x||emb]Θ + b  --> b t n f\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# STMP\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;66;03m# h = self.time_nn(x_enc)  # temporal processing: x=[b t n f] -> h=[b n f]\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;66;03m# z = self.space_nn(h, edge_index, edge_weight)  # spatial processing --> b n f\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;66;03m# CPGNN\u001b[39;00m\n\u001b[0;32m-> 1301\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCPGNN(x_enc) \u001b[38;5;66;03m# --> b n f\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;66;03m# Decoder\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_embeddings(expand\u001b[38;5;241m=\u001b[39m(b, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Papers/CGP-GNN/2023_TIDE: Time Derivative Diffusion for Deep Learning on Graphs/CPGNN_our_Imp/Final_Sent_Codes2/NOAA/layers.py:1139\u001b[0m, in \u001b[0;36mCPGNN_ST_in_TTS.forward\u001b[0;34m(self, x, L)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# Apply each of the blocks\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;66;03m# x = self.med_linear(x)\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m     x \u001b[38;5;241m=\u001b[39m b(\u001b[38;5;241m0\u001b[39m, x, x_org, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_index, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmass, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevals, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevecs, x_org)\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m# --> b t*n c_width\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \n\u001b[1;32m   1144\u001b[0m \n\u001b[1;32m   1145\u001b[0m \u001b[38;5;66;03m# Apply the last linear layer        \u001b[39;00m\n\u001b[1;32m   1146\u001b[0m x_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_lin(x) \u001b[38;5;66;03m# --> b t*n h\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Papers/CGP-GNN/2023_TIDE: Time Derivative Diffusion for Deep Learning on Graphs/CPGNN_our_Imp/Final_Sent_Codes2/NOAA/layers.py:519\u001b[0m, in \u001b[0;36mCPGNN_block_v2.forward\u001b[0;34m(self, epoch, x_in, x_original, edge_index, mass, edge_weight, evals, evecs, x0)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_in\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_width:\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor has wrong shape = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Last dim shape should have number of channels = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x_in\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_width))\n\u001b[0;32m--> 519\u001b[0m x_diff_derivative \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiff_derivative(x_in, edge_index, edge_weight, mass, evals, evecs)   \n\u001b[1;32m    521\u001b[0m x_diffuse \u001b[38;5;241m=\u001b[39m x_diff_derivative\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_MLP:\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;66;03m# Stack inputs to mlp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Papers/CGP-GNN/2023_TIDE: Time Derivative Diffusion for Deep Learning on Graphs/CPGNN_our_Imp/Final_Sent_Codes2/NOAA/layers.py:376\u001b[0m, in \u001b[0;36mTime_derivative_diffusion_product.forward\u001b[0;34m(self, x, edge_index, edge_weight, mass, evals, evecs)\u001b[0m\n\u001b[1;32m    374\u001b[0m     diffusion_coefs \u001b[38;5;241m=\u001b[39m evals_kroned\u001b[38;5;241m.\u001b[39mrepeat(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:                 \n\u001b[0;32m--> 376\u001b[0m     diffusion_coefs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(x_spec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_inout):\n\u001b[1;32m    378\u001b[0m         evals_kroned \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion_time[\u001b[38;5;241m0\u001b[39m, c] \u001b[38;5;241m*\u001b[39m evals[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(N_ITERATIONS):\n",
    "    print(100*'*' + ' iter: ' + str(i) + 100*'*')\n",
    "    one_step_gtcnn = CITRUS(input_size=1,\n",
    "                                n_nodes=n_nodes,\n",
    "                                horizon=1,\n",
    "                                emb_size=dim,\n",
    "                                hidden_size=dim,\n",
    "                                rnn_layers=1,\n",
    "                                gnn_kernel=1,\n",
    "                                mass = torch.ones(np.prod(N)).to(device),\n",
    "                                evals = evals,\n",
    "                                evecs = torch.tensor(evecs).to(device),\n",
    "                                C_width = dim,\n",
    "                                N_block = N_block,\n",
    "                                single_t = False,\n",
    "                                use_gdc = [],\n",
    "                                num_nodes = N,\n",
    "                                last_activation=torch.nn.LeakyReLU(), \n",
    "                                mlp_hidden_dims=[dim, dim, dim, dim], \n",
    "                                dropout=False, \n",
    "                                with_MLP=True, \n",
    "                                diffusion_method='spectral', \n",
    "                                device = device,\n",
    "                                graph_wise=False).to(device)\n",
    "    one_step_gtcnn.to(device)\n",
    "    print(one_step_gtcnn)\n",
    "\n",
    "    model_parameters = filter(lambda p: p.requires_grad, one_step_gtcnn.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(f\"Number of parameters: {params}\")\n",
    "\n",
    "    log_dir = f\"./runs_NOAA_w={obs_window}/{today}_lr={learning_rate}_b={batch_size}_CPGNN_dim={dim}_l={N_block}_eig1={K_list[0]}_eig2={K_list[1]}\"\n",
    "\n",
    "    check_create_folder(log_dir)\n",
    "\n",
    "    ### TRAINING ###\n",
    "    # loss_criterion = rNMSELossWithSparsityRegularizer(one_step_gtcnn, lambda_reg)\n",
    "    loss_criterion = MSELossWithSparsityRegularizer(one_step_gtcnn, lambda_value)\n",
    "\n",
    "    val_metric = rNMSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(one_step_gtcnn.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=patience, factor=factor)\n",
    "\n",
    "    best_model, best_epoch = train_model_regression(Iter=i,\n",
    "        model=one_step_gtcnn,\n",
    "        training_data=trn_data, validation_data=val_data,  # [n_samples x 1 x nodes x timesteps]\n",
    "        single_step_trn_labels=one_step_trn_labels, single_step_val_labels=one_step_val_labels,  # [n_samples x spatial_nodes]\n",
    "        num_epochs=num_epochs, batch_size=batch_size,\n",
    "        loss_criterion=loss_criterion, optimizer=optimizer, scheduler=scheduler,\n",
    "        val_metric_criterion=val_metric,\n",
    "        log_dir=log_dir,\n",
    "        not_learning_limit=not_learning_limit\n",
    "    )\n",
    "\n",
    "    rNMSE_dict, predictions_dict = compute_iteration_rNMSE(best_model, steps_ahead, tst_data_deltas, tst_labels_deltas,\n",
    "                                                           device, verbose=False)\n",
    "\n",
    "    res_dict['results'].append([round(l.item(), 4) for l in list(rNMSE_dict.values())])\n",
    "\n",
    "    means = [round(el, 4) for el in np.average(res_dict['results'], axis=0)]\n",
    "    stds = [round(el, 4) for el in np.std(res_dict['results'], axis=0)]\n",
    "    res_dict['final_res'] = {\n",
    "        'avg': means,\n",
    "        'std': stds\n",
    "    }\n",
    "\n",
    "    with open(log_dir + '/results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(res_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(res_dict['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 2544.0\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, one_step_gtcnn.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f\"Number of parameters: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  [0.9485, 0.9515, 0.9542, 0.9566, 0.9585]\n",
      "stds:  [0.0262, 0.027, 0.0272, 0.027, 0.0263]\n"
     ]
    }
   ],
   "source": [
    "# print(res_dict['results'])\n",
    "means = [round(el, 4) for el in np.average(res_dict['results'], axis=0)]\n",
    "stds = [round(el, 4) for el in np.std(res_dict['results'], axis=0)]\n",
    "print('means: ', means)\n",
    "print('stds: ', stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict['final_res'] = {\n",
    "    'avg': means,\n",
    "    'std': stds\n",
    "}\n",
    "with open(log_dir + '/results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(res_dict, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
